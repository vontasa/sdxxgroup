{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building your Recurrent Neural Network - Step by Step\n",
    "\n",
    "Welcome to Course 5's first assignment! In this assignment, you will implement your first Recurrent Neural Network in numpy.\n",
    "\n",
    "Recurrent Neural Networks (RNN) are very effective for Natural Language Processing and other sequence tasks because they have \"memory\". They can read inputs $x^{\\langle t \\rangle}$ (such as words) one at a time, and remember some information/context through the hidden layer activations that get passed from one time-step to the next. This allows a uni-directional RNN to take information from the past to process later inputs. A bidirection RNN can take context from both the past and the future. \n",
    "\n",
    "**Notation**:\n",
    "- Superscript $[l]$ denotes an object associated with the $l^{th}$ layer. \n",
    "    - Example: $a^{[4]}$ is the $4^{th}$ layer activation. $W^{[5]}$ and $b^{[5]}$ are the $5^{th}$ layer parameters.\n",
    "\n",
    "- Superscript $(i)$ denotes an object associated with the $i^{th}$ example. \n",
    "    - Example: $x^{(i)}$ is the $i^{th}$ training example input.\n",
    "\n",
    "- Superscript $\\langle t \\rangle$ denotes an object at the $t^{th}$ time-step. \n",
    "    - Example: $x^{\\langle t \\rangle}$ is the input x at the $t^{th}$ time-step. $x^{(i)\\langle t \\rangle}$ is the input at the $t^{th}$ timestep of example $i$.\n",
    "    \n",
    "- Lowerscript $i$ denotes the $i^{th}$ entry of a vector.\n",
    "    - Example: $a^{[l]}_i$ denotes the $i^{th}$ entry of the activations in layer $l$.\n",
    "\n",
    "We assume that you are already familiar with `numpy` and/or have completed the previous courses of the specialization. Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first import all the packages that you will need during this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from rnn_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Forward propagation for the basic Recurrent Neural Network\n",
    "\n",
    "Later this week, you will generate music using an RNN. The basic RNN that you will implement has the structure below. In this example, $T_x = T_y$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/RNN.png\" style=\"width:500;height:300px;\">\n",
    "<caption><center> **Figure 1**: Basic RNN model </center></caption>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how you can implement an RNN: \n",
    "\n",
    "**Steps**:\n",
    "1. Implement the calculations needed for one time-step of the RNN.\n",
    "2. Implement a loop over $T_x$ time-steps in order to process all the inputs, one at a time. \n",
    "\n",
    "Let's go!\n",
    "\n",
    "## 1.1 - RNN cell\n",
    "\n",
    "A Recurrent neural network can be seen as the repetition of a single cell. You are first going to implement the computations for a single time-step. The following figure describes the operations for a single time-step of an RNN cell. \n",
    "\n",
    "<img src=\"images/rnn_step_forward.png\" style=\"width:700px;height:300px;\">\n",
    "<caption><center> **Figure 2**: Basic RNN cell. Takes as input $x^{\\langle t \\rangle}$ (current input) and $a^{\\langle t - 1\\rangle}$ (previous hidden state containing information from the past), and outputs $a^{\\langle t \\rangle}$ which is given to the next RNN cell and also used to predict $y^{\\langle t \\rangle}$ </center></caption>\n",
    "\n",
    "**Exercise**: Implement the RNN-cell described in Figure (2).\n",
    "\n",
    "**Instructions**:\n",
    "1. Compute the hidden state with tanh activation: $a^{\\langle t \\rangle} = \\tanh(W_{aa} a^{\\langle t-1 \\rangle} + W_{ax} x^{\\langle t \\rangle} + b_a)$.\n",
    "2. Using your new hidden state $a^{\\langle t \\rangle}$, compute the prediction $\\hat{y}^{\\langle t \\rangle} = softmax(W_{ya} a^{\\langle t \\rangle} + b_y)$. We provided you a function: `softmax`.\n",
    "3. Store $(a^{\\langle t \\rangle}, a^{\\langle t-1 \\rangle}, x^{\\langle t \\rangle}, parameters)$ in cache\n",
    "4. Return $a^{\\langle t \\rangle}$ , $y^{\\langle t \\rangle}$ and cache\n",
    "\n",
    "We will vectorize over $m$ examples. Thus, $x^{\\langle t \\rangle}$ will have dimension $(n_x,m)$, and $a^{\\langle t \\rangle}$ will have dimension $(n_a,m)$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: rnn_cell_forward\n",
    "\n",
    "def rnn_cell_forward(xt, a_prev, parameters):\n",
    "    \"\"\"\n",
    "    Implements a single forward step of the RNN-cell as described in Figure (2)\n",
    "\n",
    "    Arguments:\n",
    "    xt -- your input data at timestep \"t\", numpy array of shape (n_x, m).\n",
    "    a_prev -- Hidden state at timestep \"t-1\", numpy array of shape (n_a, m)\n",
    "    parameters -- python dictionary containing:\n",
    "                        Wax -- Weight matrix multiplying the input, numpy array of shape (n_a, n_x)\n",
    "                        Waa -- Weight matrix multiplying the hidden state, numpy array of shape (n_a, n_a)\n",
    "                        Wya -- Weight matrix relating the hidden-state to the output, numpy array of shape (n_y, n_a)\n",
    "                        ba --  Bias, numpy array of shape (n_a, 1)\n",
    "                        by -- Bias relating the hidden-state to the output, numpy array of shape (n_y, 1)\n",
    "    Returns:\n",
    "    a_next -- next hidden state, of shape (n_a, m)\n",
    "    yt_pred -- prediction at timestep \"t\", numpy array of shape (n_y, m)\n",
    "    cache -- tuple of values needed for the backward pass, contains (a_next, a_prev, xt, parameters)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve parameters from \"parameters\"\n",
    "    Wax = parameters[\"Wax\"]\n",
    "    Waa = parameters[\"Waa\"]\n",
    "    Wya = parameters[\"Wya\"]\n",
    "    ba = parameters[\"ba\"]\n",
    "    by = parameters[\"by\"]\n",
    "    \n",
    "    ### START CODE HERE ### (≈2 lines)\n",
    "    # compute next activation state using the formula given above\n",
    "    a_next = np.tanh(np.matmul(Waa, a_prev)+np.matmul(Wax,xt)+ba)\n",
    "    # compute output of the current cell using the formula given above\n",
    "    yt_pred = softmax(np.matmul(Wya,a_next)+by)   \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # store values you need for backward propagation in cache\n",
    "    cache = (a_next, a_prev, xt, parameters)\n",
    "    \n",
    "    return a_next, yt_pred, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_next[4] =  [ 0.59584544  0.18141802  0.61311866  0.99808218  0.85016201  0.99980978\n",
      " -0.18887155  0.99815551  0.6531151   0.82872037]\n",
      "a_next.shape =  (5, 10)\n",
      "yt_pred[1] = [ 0.9888161   0.01682021  0.21140899  0.36817467  0.98988387  0.88945212\n",
      "  0.36920224  0.9966312   0.9982559   0.17746526]\n",
      "yt_pred.shape =  (2, 10)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "xt = np.random.randn(3,10)\n",
    "a_prev = np.random.randn(5,10)\n",
    "Waa = np.random.randn(5,5)\n",
    "Wax = np.random.randn(5,3)\n",
    "Wya = np.random.randn(2,5)\n",
    "ba = np.random.randn(5,1)\n",
    "by = np.random.randn(2,1)\n",
    "parameters = {\"Waa\": Waa, \"Wax\": Wax, \"Wya\": Wya, \"ba\": ba, \"by\": by}\n",
    "\n",
    "a_next, yt_pred, cache = rnn_cell_forward(xt, a_prev, parameters)\n",
    "print(\"a_next[4] = \", a_next[4])\n",
    "print(\"a_next.shape = \", a_next.shape)\n",
    "print(\"yt_pred[1] =\", yt_pred[1])\n",
    "print(\"yt_pred.shape = \", yt_pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**: \n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **a_next[4]**:\n",
    "        </td>\n",
    "        <td>\n",
    "           [ 0.59584544  0.18141802  0.61311866  0.99808218  0.85016201  0.99980978\n",
    " -0.18887155  0.99815551  0.6531151   0.82872037]\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **a_next.shape**:\n",
    "        </td>\n",
    "        <td>\n",
    "           (5, 10)\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **yt[1]**:\n",
    "        </td>\n",
    "        <td>\n",
    "           [ 0.9888161   0.01682021  0.21140899  0.36817467  0.98988387  0.88945212\n",
    "  0.36920224  0.9966312   0.9982559   0.17746526]\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **yt.shape**:\n",
    "        </td>\n",
    "        <td>\n",
    "           (2, 10)\n",
    "        </td>\n",
    "    </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 - RNN forward pass \n",
    "\n",
    "You can see an RNN as the repetition of the cell you've just built. If your input sequence of data is carried over 10 time steps, then you will copy the RNN cell 10 times. Each cell takes as input the hidden state from the previous cell ($a^{\\langle t-1 \\rangle}$) and the current time-step's input data ($x^{\\langle t \\rangle}$). It outputs a hidden state ($a^{\\langle t \\rangle}$) and a prediction ($y^{\\langle t \\rangle}$) for this time-step.\n",
    "\n",
    "\n",
    "<img src=\"images/rnn.png\" style=\"width:800px;height:300px;\">\n",
    "<caption><center> **Figure 3**: Basic RNN. The input sequence $x = (x^{\\langle 1 \\rangle}, x^{\\langle 2 \\rangle}, ..., x^{\\langle T_x \\rangle})$  is carried over $T_x$ time steps. The network outputs $y = (y^{\\langle 1 \\rangle}, y^{\\langle 2 \\rangle}, ..., y^{\\langle T_x \\rangle})$. </center></caption>\n",
    "\n",
    "\n",
    "\n",
    "**Exercise**: Code the forward propagation of the RNN described in Figure (3).\n",
    "\n",
    "**Instructions**:\n",
    "1. Create a vector of zeros ($a$) that will store all the hidden states computed by the RNN.\n",
    "2. Initialize the \"next\" hidden state as $a_0$ (initial hidden state).\n",
    "3. Start looping over each time step, your incremental index is $t$ :\n",
    "    - Update the \"next\" hidden state and the cache by running `rnn_cell_forward`\n",
    "    - Store the \"next\" hidden state in $a$ ($t^{th}$ position) \n",
    "    - Store the prediction in y\n",
    "    - Add the cache to the list of caches\n",
    "4. Return $a$, $y$ and caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: rnn_forward\n",
    "\n",
    "def rnn_forward(x, a0, parameters):\n",
    "    \"\"\"\n",
    "    Implement the forward propagation of the recurrent neural network described in Figure (3).\n",
    "\n",
    "    Arguments:\n",
    "    x -- Input data for every time-step, of shape (n_x, m, T_x).\n",
    "    a0 -- Initial hidden state, of shape (n_a, m)\n",
    "    parameters -- python dictionary containing:\n",
    "                        Waa -- Weight matrix multiplying the hidden state, numpy array of shape (n_a, n_a)\n",
    "                        Wax -- Weight matrix multiplying the input, numpy array of shape (n_a, n_x)\n",
    "                        Wya -- Weight matrix relating the hidden-state to the output, numpy array of shape (n_y, n_a)\n",
    "                        ba --  Bias numpy array of shape (n_a, 1)\n",
    "                        by -- Bias relating the hidden-state to the output, numpy array of shape (n_y, 1)\n",
    "\n",
    "    Returns:\n",
    "    a -- Hidden states for every time-step, numpy array of shape (n_a, m, T_x)\n",
    "    y_pred -- Predictions for every time-step, numpy array of shape (n_y, m, T_x)\n",
    "    caches -- tuple of values needed for the backward pass, contains (list of caches, x)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize \"caches\" which will contain the list of all caches\n",
    "    caches = []\n",
    "    \n",
    "    # Retrieve dimensions from shapes of x and parameters[\"Wya\"]\n",
    "    n_x, m, T_x = x.shape\n",
    "    n_y, n_a = parameters[\"Wya\"].shape\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    # initialize \"a\" and \"y\" with zeros (≈2 lines)\n",
    "    a = np.zeros((n_a,m,T_x))\n",
    "    y_pred = np.zeros((n_y, m,T_x))\n",
    "    \n",
    "    # Initialize a_next (≈1 line)\n",
    "    a_next = a0\n",
    "    \n",
    "    # loop over all time-steps\n",
    "    for t in range(T_x):\n",
    "        # Update next hidden state, compute the prediction, get the cache (≈1 line)\n",
    "        a_next, yt_pred, cache = rnn_cell_forward(x[:,:,t], a_next, parameters)\n",
    "        # Save the value of the new \"next\" hidden state in a (≈1 line)\n",
    "        a[:,:,t] = a_next\n",
    "        # Save the value of the prediction in y (≈1 line)\n",
    "        y_pred[:,:,t] = yt_pred\n",
    "        # Append \"cache\" to \"caches\" (≈1 line)\n",
    "        caches.append(cache)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # store values needed for backward propagation in cache\n",
    "    caches = (caches, x)\n",
    "    \n",
    "    return a, y_pred, caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a[4][1] =  [-0.99999375  0.77911235 -0.99861469 -0.99833267]\n",
      "a.shape =  (5, 10, 4)\n",
      "y_pred[1][3] = [ 0.79560373  0.86224861  0.11118257  0.81515947]\n",
      "y_pred.shape =  (2, 10, 4)\n",
      "caches[1][1][3] = [-1.1425182  -0.34934272 -0.20889423  0.58662319]\n",
      "len(caches) =  2\n",
      "[(array([[-0.94679727,  0.52566384,  0.84483137,  0.95268814,  0.99996124,\n",
      "         0.94354992, -0.31399689,  0.9985362 ,  0.99995626,  0.99981346],\n",
      "       [ 0.9017533 , -0.64008899, -0.61107796,  0.69254271,  0.99323355,\n",
      "        -0.97376282,  0.96905989,  0.63387486,  0.34250436, -0.83173001],\n",
      "       [ 0.97087407,  0.32586574,  0.94009082,  0.97102425,  0.99869819,\n",
      "        -0.9227938 , -0.97880697, -0.78819779,  0.99957809, -0.84758466],\n",
      "       [-0.9104497 , -0.96081056, -0.93837279,  0.9957971 ,  0.84483456,\n",
      "         0.98777081, -0.73832733, -0.99876665,  0.41236695,  0.93310421],\n",
      "       [-0.99935897, -0.99999375,  0.98895163,  0.9999802 , -0.9912801 ,\n",
      "         0.74865774, -0.96279238, -0.99251598,  0.93272501, -0.1343305 ]]), array([[-0.02461696, -0.77516162,  1.27375593,  1.96710175, -1.85798186,\n",
      "         1.23616403,  1.62765075,  0.3380117 , -1.19926803,  0.86334532],\n",
      "       [-0.1809203 , -0.60392063, -1.23005814,  0.5505375 ,  0.79280687,\n",
      "        -0.62353073,  0.52057634, -1.14434139,  0.80186103,  0.0465673 ],\n",
      "       [-0.18656977, -0.10174587,  0.86888616,  0.75041164,  0.52946532,\n",
      "         0.13770121,  0.07782113,  0.61838026,  0.23249456,  0.68255141],\n",
      "       [-0.31011677, -2.43483776,  1.0388246 ,  2.18697965,  0.44136444,\n",
      "        -0.10015523, -0.13644474, -0.11905419,  0.01740941, -1.12201873],\n",
      "       [-0.51709446, -0.99702683,  0.24879916, -0.29664115,  0.49521132,\n",
      "        -0.17470316,  0.98633519,  0.2135339 ,  2.19069973, -1.89636092]]), array([[ 1.62434536,  0.86540763,  0.3190391 , -0.3224172 , -0.17242821,\n",
      "        -1.10061918,  0.90085595, -0.26788808, -0.6871727 , -1.11731035],\n",
      "       [-0.19183555,  0.05080775,  0.12015895, -1.1425182 ,  0.83898341,\n",
      "        -0.75439794,  0.48851815,  2.18557541,  0.16003707, -0.30620401],\n",
      "       [-0.22232814,  0.19829972,  0.12182127, -0.37528495, -0.34385368,\n",
      "        -0.44712856, -1.09491185, -0.26621851,  0.84616065, -0.03869551]]), {'Waa': array([[-0.64691669,  0.90148689,  2.52832571, -0.24863478,  0.04366899],\n",
      "       [-0.22631424,  1.33145711, -0.28730786,  0.68006984, -0.3198016 ],\n",
      "       [-1.27255876,  0.31354772,  0.50318481,  1.29322588, -0.11044703],\n",
      "       [-0.61736206,  0.5627611 ,  0.24073709,  0.28066508, -0.0731127 ],\n",
      "       [ 1.16033857,  0.36949272,  1.90465871,  1.1110567 ,  0.6590498 ]]), 'Wax': array([[-1.62743834,  0.60231928,  0.4202822 ],\n",
      "       [ 0.81095167,  1.04444209, -0.40087819],\n",
      "       [ 0.82400562, -0.56230543,  1.95487808],\n",
      "       [-1.33195167, -1.76068856, -1.65072127],\n",
      "       [-0.89055558, -1.1191154 ,  1.9560789 ]]), 'Wya': array([[-0.3264995 , -1.34267579,  1.11438298, -0.58652394, -1.23685338],\n",
      "       [ 0.87583893,  0.62336218, -0.43495668,  1.40754   ,  0.12910158]]), 'ba': array([[ 1.6169496 ],\n",
      "       [ 0.50274088],\n",
      "       [ 1.55880554],\n",
      "       [ 0.1094027 ],\n",
      "       [-1.2197444 ]]), 'by': array([[ 2.44936865],\n",
      "       [-0.54577417]])}), (array([[ 0.99998902,  0.99993012,  0.99971338,  0.9993585 ,  0.9999908 ,\n",
      "        -0.99516219,  0.90494133, -0.95921363,  0.99994879, -0.99139889],\n",
      "       [-0.0035545 , -0.99808521, -0.93987579,  0.70004749,  0.98511719,\n",
      "         0.89291419,  0.84821902, -0.0561147 ,  0.76229843,  0.94604565],\n",
      "       [ 0.96868192, -0.91931824,  0.79972708,  0.69671275,  0.81461615,\n",
      "         0.99784354,  0.62394864,  0.19186314, -0.91253018, -0.98924985],\n",
      "       [ 0.99927595,  0.99726769, -0.99812032,  0.98744174,  0.05888194,\n",
      "        -0.99999738,  0.84553649,  0.81798993,  0.75086186, -0.01108915],\n",
      "       [-0.57882882,  0.77911235,  0.9905525 ,  0.99693738,  0.98087418,\n",
      "        -0.59005528, -0.99825059, -0.95934467,  0.81262652, -0.99995298]]), array([[-0.94679727,  0.52566384,  0.84483137,  0.95268814,  0.99996124,\n",
      "         0.94354992, -0.31399689,  0.9985362 ,  0.99995626,  0.99981346],\n",
      "       [ 0.9017533 , -0.64008899, -0.61107796,  0.69254271,  0.99323355,\n",
      "        -0.97376282,  0.96905989,  0.63387486,  0.34250436, -0.83173001],\n",
      "       [ 0.97087407,  0.32586574,  0.94009082,  0.97102425,  0.99869819,\n",
      "        -0.9227938 , -0.97880697, -0.78819779,  0.99957809, -0.84758466],\n",
      "       [-0.9104497 , -0.96081056, -0.93837279,  0.9957971 ,  0.84483456,\n",
      "         0.98777081, -0.73832733, -0.99876665,  0.41236695,  0.93310421],\n",
      "       [-0.99935897, -0.99999375,  0.98895163,  0.9999802 , -0.9912801 ,\n",
      "         0.74865774, -0.96279238, -0.99251598,  0.93272501, -0.1343305 ]]), array([[-0.61175641, -2.3015387 , -0.24937038, -0.38405435, -0.87785842,\n",
      "         1.14472371, -0.68372786,  0.53035547, -0.84520564,  0.2344157 ],\n",
      "       [-0.88762896, -0.63699565,  0.61720311, -0.34934272,  0.93110208,\n",
      "         1.25286816, -0.07557171, -1.39649634,  0.87616892,  0.82797464],\n",
      "       [-0.20075807,  0.11900865,  1.12948391, -0.63873041,  0.04359686,\n",
      "         1.2245077 ,  0.16938243,  0.03261455, -0.85951594, -1.61577235]]), {'Waa': array([[-0.64691669,  0.90148689,  2.52832571, -0.24863478,  0.04366899],\n",
      "       [-0.22631424,  1.33145711, -0.28730786,  0.68006984, -0.3198016 ],\n",
      "       [-1.27255876,  0.31354772,  0.50318481,  1.29322588, -0.11044703],\n",
      "       [-0.61736206,  0.5627611 ,  0.24073709,  0.28066508, -0.0731127 ],\n",
      "       [ 1.16033857,  0.36949272,  1.90465871,  1.1110567 ,  0.6590498 ]]), 'Wax': array([[-1.62743834,  0.60231928,  0.4202822 ],\n",
      "       [ 0.81095167,  1.04444209, -0.40087819],\n",
      "       [ 0.82400562, -0.56230543,  1.95487808],\n",
      "       [-1.33195167, -1.76068856, -1.65072127],\n",
      "       [-0.89055558, -1.1191154 ,  1.9560789 ]]), 'Wya': array([[-0.3264995 , -1.34267579,  1.11438298, -0.58652394, -1.23685338],\n",
      "       [ 0.87583893,  0.62336218, -0.43495668,  1.40754   ,  0.12910158]]), 'ba': array([[ 1.6169496 ],\n",
      "       [ 0.50274088],\n",
      "       [ 1.55880554],\n",
      "       [ 0.1094027 ],\n",
      "       [-1.2197444 ]]), 'by': array([[ 2.44936865],\n",
      "       [-0.54577417]])}), (array([[ 0.99859532, -0.99996484,  0.63006186,  0.87825787,  0.99897665,\n",
      "         0.99987056,  0.99964112,  0.97076661,  0.55718656, -0.90908533],\n",
      "       [-0.40146936,  0.90937915, -0.82797531,  0.95560602,  0.93041097,\n",
      "         0.9777595 ,  0.99428756, -0.06557296,  0.89552076,  0.99882607],\n",
      "       [ 0.9860278 ,  0.62536152,  0.98280633,  0.99918672, -0.34958752,\n",
      "         0.99857354,  0.99397484,  0.91860743,  0.71732866,  0.99999082],\n",
      "       [ 0.94217573, -0.98947737, -0.99997534, -0.91907333,  0.57284256,\n",
      "        -0.91229958, -0.98818114,  0.99999724, -0.36929754, -0.99769046],\n",
      "       [ 0.99953622, -0.99861469,  0.87805502,  0.99745184,  0.76076959,\n",
      "        -0.97721203,  0.95668547, -0.97402324,  0.65510908, -0.9994704 ]]), array([[ 0.99998902,  0.99993012,  0.99971338,  0.9993585 ,  0.9999908 ,\n",
      "        -0.99516219,  0.90494133, -0.95921363,  0.99994879, -0.99139889],\n",
      "       [-0.0035545 , -0.99808521, -0.93987579,  0.70004749,  0.98511719,\n",
      "         0.89291419,  0.84821902, -0.0561147 ,  0.76229843,  0.94604565],\n",
      "       [ 0.96868192, -0.91931824,  0.79972708,  0.69671275,  0.81461615,\n",
      "         0.99784354,  0.62394864,  0.19186314, -0.91253018, -0.98924985],\n",
      "       [ 0.99927595,  0.99726769, -0.99812032,  0.98744174,  0.05888194,\n",
      "        -0.99999738,  0.84553649,  0.81798993,  0.75086186, -0.01108915],\n",
      "       [-0.57882882,  0.77911235,  0.9905525 ,  0.99693738,  0.98087418,\n",
      "        -0.59005528, -0.99825059, -0.95934467,  0.81262652, -0.99995298]]), array([[-0.52817175,  1.74481176,  1.46210794,  1.13376944,  0.04221375,\n",
      "         0.90159072, -0.12289023, -0.69166075, -0.67124613,  1.65980218],\n",
      "       [-0.74715829,  0.19091548,  0.30017032, -0.20889423,  0.28558733,\n",
      "         0.51292982,  1.13162939, -1.44411381,  0.31563495,  0.23009474],\n",
      "       [ 0.18656139, -0.67066229,  1.19891788,  0.42349435, -0.62000084,\n",
      "         0.40349164,  0.74055645, -1.37311732,  0.35054598,  1.12141771]]), {'Waa': array([[-0.64691669,  0.90148689,  2.52832571, -0.24863478,  0.04366899],\n",
      "       [-0.22631424,  1.33145711, -0.28730786,  0.68006984, -0.3198016 ],\n",
      "       [-1.27255876,  0.31354772,  0.50318481,  1.29322588, -0.11044703],\n",
      "       [-0.61736206,  0.5627611 ,  0.24073709,  0.28066508, -0.0731127 ],\n",
      "       [ 1.16033857,  0.36949272,  1.90465871,  1.1110567 ,  0.6590498 ]]), 'Wax': array([[-1.62743834,  0.60231928,  0.4202822 ],\n",
      "       [ 0.81095167,  1.04444209, -0.40087819],\n",
      "       [ 0.82400562, -0.56230543,  1.95487808],\n",
      "       [-1.33195167, -1.76068856, -1.65072127],\n",
      "       [-0.89055558, -1.1191154 ,  1.9560789 ]]), 'Wya': array([[-0.3264995 , -1.34267579,  1.11438298, -0.58652394, -1.23685338],\n",
      "       [ 0.87583893,  0.62336218, -0.43495668,  1.40754   ,  0.12910158]]), 'ba': array([[ 1.6169496 ],\n",
      "       [ 0.50274088],\n",
      "       [ 1.55880554],\n",
      "       [ 0.1094027 ],\n",
      "       [-1.2197444 ]]), 'by': array([[ 2.44936865],\n",
      "       [-0.54577417]])}), (array([[ 0.99998339,  0.99999942,  0.99999504,  0.9999979 ,  0.6007902 ,\n",
      "         0.99902443,  0.999997  ,  0.99792727,  0.97797982,  0.99994617],\n",
      "       [ 0.47240999,  0.99308063, -0.99944897,  0.03494921,  0.99371087,\n",
      "         0.68670555,  0.91339115, -0.0515541 , -0.60056774,  0.98957886],\n",
      "       [ 0.62437977,  0.83109594, -0.9114071 , -0.81446397,  0.98390801,\n",
      "         0.94312789, -0.99894842,  0.9916753 , -0.45986869,  0.99746386],\n",
      "       [-0.98743686, -0.97175622,  0.9759714 ,  0.30870646, -0.99798536,\n",
      "        -0.77235035,  0.08833992,  0.73642847,  0.99998852, -0.94005036],\n",
      "       [ 0.99692362, -0.99833267,  0.99623046,  0.97406138,  0.54482277,\n",
      "         0.92063859, -0.76146336,  0.99861032,  0.69252916, -0.98612292]]), array([[ 0.99859532, -0.99996484,  0.63006186,  0.87825787,  0.99897665,\n",
      "         0.99987056,  0.99964112,  0.97076661,  0.55718656, -0.90908533],\n",
      "       [-0.40146936,  0.90937915, -0.82797531,  0.95560602,  0.93041097,\n",
      "         0.9777595 ,  0.99428756, -0.06557296,  0.89552076,  0.99882607],\n",
      "       [ 0.9860278 ,  0.62536152,  0.98280633,  0.99918672, -0.34958752,\n",
      "         0.99857354,  0.99397484,  0.91860743,  0.71732866,  0.99999082],\n",
      "       [ 0.94217573, -0.98947737, -0.99997534, -0.91907333,  0.57284256,\n",
      "        -0.91229958, -0.98818114,  0.99999724, -0.36929754, -0.99769046],\n",
      "       [ 0.99953622, -0.99861469,  0.87805502,  0.99745184,  0.76076959,\n",
      "        -0.97721203,  0.95668547, -0.97402324,  0.65510908, -0.9994704 ]]), array([[-1.07296862, -0.7612069 , -2.06014071, -1.09989127,  0.58281521,\n",
      "         0.50249434, -0.93576943, -0.39675353, -0.0126646 ,  0.74204416],\n",
      "       [ 1.6924546 ,  2.10025514, -0.35224985,  0.58662319,  0.88514116,\n",
      "        -0.29809284,  1.51981682, -0.50446586, -2.02220122,  0.76201118],\n",
      "       [ 0.41005165,  0.37756379,  0.18515642,  0.07734007,  0.69803203,\n",
      "         0.59357852, -0.9537006 ,  0.31515939, -1.31228341,  0.40890054]]), {'Waa': array([[-0.64691669,  0.90148689,  2.52832571, -0.24863478,  0.04366899],\n",
      "       [-0.22631424,  1.33145711, -0.28730786,  0.68006984, -0.3198016 ],\n",
      "       [-1.27255876,  0.31354772,  0.50318481,  1.29322588, -0.11044703],\n",
      "       [-0.61736206,  0.5627611 ,  0.24073709,  0.28066508, -0.0731127 ],\n",
      "       [ 1.16033857,  0.36949272,  1.90465871,  1.1110567 ,  0.6590498 ]]), 'Wax': array([[-1.62743834,  0.60231928,  0.4202822 ],\n",
      "       [ 0.81095167,  1.04444209, -0.40087819],\n",
      "       [ 0.82400562, -0.56230543,  1.95487808],\n",
      "       [-1.33195167, -1.76068856, -1.65072127],\n",
      "       [-0.89055558, -1.1191154 ,  1.9560789 ]]), 'Wya': array([[-0.3264995 , -1.34267579,  1.11438298, -0.58652394, -1.23685338],\n",
      "       [ 0.87583893,  0.62336218, -0.43495668,  1.40754   ,  0.12910158]]), 'ba': array([[ 1.6169496 ],\n",
      "       [ 0.50274088],\n",
      "       [ 1.55880554],\n",
      "       [ 0.1094027 ],\n",
      "       [-1.2197444 ]]), 'by': array([[ 2.44936865],\n",
      "       [-0.54577417]])})]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "x = np.random.randn(3,10,4)\n",
    "a0 = np.random.randn(5,10)\n",
    "Waa = np.random.randn(5,5)\n",
    "Wax = np.random.randn(5,3)\n",
    "Wya = np.random.randn(2,5)\n",
    "ba = np.random.randn(5,1)\n",
    "by = np.random.randn(2,1)\n",
    "parameters = {\"Waa\": Waa, \"Wax\": Wax, \"Wya\": Wya, \"ba\": ba, \"by\": by}\n",
    "\n",
    "a, y_pred, caches = rnn_forward(x, a0, parameters)\n",
    "print(\"a[4][1] = \", a[4][1])\n",
    "print(\"a.shape = \", a.shape)\n",
    "print(\"y_pred[1][3] =\", y_pred[1][3])\n",
    "print(\"y_pred.shape = \", y_pred.shape)\n",
    "print(\"caches[1][1][3] =\", caches[1][1][3])\n",
    "print(\"len(caches) = \", len(caches))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **a[4][1]**:\n",
    "        </td>\n",
    "        <td>\n",
    "           [-0.99999375  0.77911235 -0.99861469 -0.99833267]\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **a.shape**:\n",
    "        </td>\n",
    "        <td>\n",
    "           (5, 10, 4)\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **y[1][3]**:\n",
    "        </td>\n",
    "        <td>\n",
    "           [ 0.79560373  0.86224861  0.11118257  0.81515947]\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **y.shape**:\n",
    "        </td>\n",
    "        <td>\n",
    "           (2, 10, 4)\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **cache[1][1][3]**:\n",
    "        </td>\n",
    "        <td>\n",
    "           [-1.1425182  -0.34934272 -0.20889423  0.58662319]\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **len(cache)**:\n",
    "        </td>\n",
    "        <td>\n",
    "           2\n",
    "        </td>\n",
    "    </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You've successfully built the forward propagation of a recurrent neural network from scratch. This will work well enough for some applications, but it suffers from vanishing gradient problems. So it works best when each output $y^{\\langle t \\rangle}$ can be estimated using mainly \"local\" context (meaning information from inputs $x^{\\langle t' \\rangle}$ where $t'$ is not too far from $t$). \n",
    "\n",
    "In the next part, you will build a more complex LSTM model, which is better at addressing vanishing gradients. The LSTM will be better able to remember a piece of information and keep it saved for many timesteps. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Long Short-Term Memory (LSTM) network\n",
    "\n",
    "This following figure shows the operations of an LSTM-cell.\n",
    "\n",
    "<img src=\"images/LSTM.png\" style=\"width:500;height:400px;\">\n",
    "<caption><center> **Figure 4**: LSTM-cell. This tracks and updates a \"cell state\" or memory variable $c^{\\langle t \\rangle}$ at every time-step, which can be different from $a^{\\langle t \\rangle}$. </center></caption>\n",
    "\n",
    "Similar to the RNN example above, you will start by implementing the LSTM cell for a single time-step. Then you can iteratively call it from inside a for-loop to have it process an input with $T_x$ time-steps. \n",
    "\n",
    "### About the gates\n",
    "\n",
    "#### - Forget gate\n",
    "\n",
    "For the sake of this illustration, lets assume we are reading words in a piece of text, and want use an LSTM to keep track of grammatical structures, such as whether the subject is singular or plural. If the subject changes from a singular word to a plural word, we need to find a way to get rid of our previously stored memory value of the singular/plural state. In an LSTM, the forget gate lets us do this: \n",
    "\n",
    "$$\\Gamma_f^{\\langle t \\rangle} = \\sigma(W_f[a^{\\langle t-1 \\rangle}, x^{\\langle t \\rangle}] + b_f)\\tag{1} $$\n",
    "\n",
    "Here, $W_f$ are weights that govern the forget gate's behavior. We concatenate $[a^{\\langle t-1 \\rangle}, x^{\\langle t \\rangle}]$ and multiply by $W_f$. The equation above results in a vector $\\Gamma_f^{\\langle t \\rangle}$ with values between 0 and 1. This forget gate vector will be multiplied element-wise by the previous cell state $c^{\\langle t-1 \\rangle}$. So if one of the values of $\\Gamma_f^{\\langle t \\rangle}$ is 0 (or close to 0) then it means that the LSTM should remove that piece of information (e.g. the singular subject) in the corresponding component of $c^{\\langle t-1 \\rangle}$. If one of the values is 1, then it will keep the information. \n",
    "\n",
    "#### - Update gate\n",
    "\n",
    "Once we forget that the subject being discussed is singular, we need to find a way to update it to reflect that the new subject is now plural. Here is the formulat for the update gate: \n",
    "\n",
    "$$\\Gamma_u^{\\langle t \\rangle} = \\sigma(W_u[a^{\\langle t-1 \\rangle}, x^{\\{t\\}}] + b_u)\\tag{2} $$ \n",
    "\n",
    "Similar to the forget gate, here $\\Gamma_u^{\\langle t \\rangle}$ is again a vector of values between 0 and 1. This will be multiplied element-wise with $\\tilde{c}^{\\langle t \\rangle}$, in order to compute $c^{\\langle t \\rangle}$.\n",
    "\n",
    "#### - Updating the cell \n",
    "\n",
    "To update the new subject we need to create a new vector of numbers that we can add to our previous cell state. The equation we use is: \n",
    "\n",
    "$$ \\tilde{c}^{\\langle t \\rangle} = \\tanh(W_c[a^{\\langle t-1 \\rangle}, x^{\\langle t \\rangle}] + b_c)\\tag{3} $$\n",
    "\n",
    "Finally, the new cell state is: \n",
    "\n",
    "$$ c^{\\langle t \\rangle} = \\Gamma_f^{\\langle t \\rangle}* c^{\\langle t-1 \\rangle} + \\Gamma_u^{\\langle t \\rangle} *\\tilde{c}^{\\langle t \\rangle} \\tag{4} $$\n",
    "\n",
    "\n",
    "#### - Output gate\n",
    "\n",
    "To decide which outputs we will use, we will use the following two formulas: \n",
    "\n",
    "$$ \\Gamma_o^{\\langle t \\rangle}=  \\sigma(W_o[a^{\\langle t-1 \\rangle}, x^{\\langle t \\rangle}] + b_o)\\tag{5}$$ \n",
    "$$ a^{\\langle t \\rangle} = \\Gamma_o^{\\langle t \\rangle}* \\tanh(c^{\\langle t \\rangle})\\tag{6} $$\n",
    "\n",
    "Where in equation 5 you decide what to output using a sigmoid function and in equation 6 you multiply that by the $\\tanh$ of the previous state. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 - LSTM cell\n",
    "\n",
    "**Exercise**: Implement the LSTM cell described in the Figure (3).\n",
    "\n",
    "**Instructions**:\n",
    "1. Concatenate $a^{\\langle t-1 \\rangle}$ and $x^{\\langle t \\rangle}$ in a single matrix: $concat = \\begin{bmatrix} a^{\\langle t-1 \\rangle} \\\\ x^{\\langle t \\rangle} \\end{bmatrix}$\n",
    "2. Compute all the formulas 1-6. You can use `sigmoid()` (provided) and `np.tanh()`.\n",
    "3. Compute the prediction $y^{\\langle t \\rangle}$. You can use `softmax()` (provided)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: lstm_cell_forward\n",
    "\n",
    "def lstm_cell_forward(xt, a_prev, c_prev, parameters):\n",
    "    \"\"\"\n",
    "    Implement a single forward step of the LSTM-cell as described in Figure (4)\n",
    "\n",
    "    Arguments:\n",
    "    xt -- your input data at timestep \"t\", numpy array of shape (n_x, m).\n",
    "    a_prev -- Hidden state at timestep \"t-1\", numpy array of shape (n_a, m)\n",
    "    c_prev -- Memory state at timestep \"t-1\", numpy array of shape (n_a, m)\n",
    "    parameters -- python dictionary containing:\n",
    "                        Wf -- Weight matrix of the forget gate, numpy array of shape (n_a, n_a + n_x)\n",
    "                        bf -- Bias of the forget gate, numpy array of shape (n_a, 1)\n",
    "                        Wi -- Weight matrix of the update gate, numpy array of shape (n_a, n_a + n_x)\n",
    "                        bi -- Bias of the update gate, numpy array of shape (n_a, 1)\n",
    "                        Wc -- Weight matrix of the first \"tanh\", numpy array of shape (n_a, n_a + n_x)\n",
    "                        bc --  Bias of the first \"tanh\", numpy array of shape (n_a, 1)\n",
    "                        Wo -- Weight matrix of the output gate, numpy array of shape (n_a, n_a + n_x)\n",
    "                        bo --  Bias of the output gate, numpy array of shape (n_a, 1)\n",
    "                        Wy -- Weight matrix relating the hidden-state to the output, numpy array of shape (n_y, n_a)\n",
    "                        by -- Bias relating the hidden-state to the output, numpy array of shape (n_y, 1)\n",
    "                        \n",
    "    Returns:\n",
    "    a_next -- next hidden state, of shape (n_a, m)\n",
    "    c_next -- next memory state, of shape (n_a, m)\n",
    "    yt_pred -- prediction at timestep \"t\", numpy array of shape (n_y, m)\n",
    "    cache -- tuple of values needed for the backward pass, contains (a_next, c_next, a_prev, c_prev, xt, parameters)\n",
    "    \n",
    "    Note: ft/it/ot stand for the forget/update/output gates, cct stands for the candidate value (c tilde),\n",
    "          c stands for the memory value\n",
    "    \"\"\"\n",
    "\n",
    "    # Retrieve parameters from \"parameters\"\n",
    "    Wf = parameters[\"Wf\"]\n",
    "    bf = parameters[\"bf\"]\n",
    "    Wi = parameters[\"Wi\"]\n",
    "    bi = parameters[\"bi\"]\n",
    "    Wc = parameters[\"Wc\"]\n",
    "    bc = parameters[\"bc\"]\n",
    "    Wo = parameters[\"Wo\"]\n",
    "    bo = parameters[\"bo\"]\n",
    "    Wy = parameters[\"Wy\"]\n",
    "    by = parameters[\"by\"]\n",
    "    \n",
    "    # Retrieve dimensions from shapes of xt and Wy\n",
    "    n_x, m = xt.shape\n",
    "    n_y, n_a = Wy.shape\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "    # Concatenate a_prev and xt (≈3 lines)\n",
    "    concat = np.zeros((n_a+n_x, m))\n",
    "    concat[: n_a, :] = a_prev\n",
    "    concat[n_a :, :] = xt\n",
    "\n",
    "    # Compute values for ft, it, cct, c_next, ot, a_next using the formulas given figure (4) (≈6 lines)\n",
    "    ft = sigmoid(np.matmul(Wf, concat) + bf)\n",
    "    it = sigmoid(np.matmul(Wi, concat) + bi)\n",
    "    cct = np.tanh(np.matmul(Wc, concat) + bc)\n",
    "    c_next = ft * c_prev + it * cct\n",
    "    ot = sigmoid(np.matmul(Wo, concat) + bo)\n",
    "    a_next = ot * np.tanh(c_next)\n",
    "    \n",
    "    # Compute prediction of the LSTM cell (≈1 line)\n",
    "    yt_pred = softmax(np.dot(Wy, a_next)+by)\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # store values needed for backward propagation in cache\n",
    "    cache = (a_next, c_next, a_prev, c_prev, ft, it, cct, ot, xt, parameters)\n",
    "\n",
    "    return a_next, c_next, yt_pred, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_next[4] =  [-0.66408471  0.0036921   0.02088357  0.22834167 -0.85575339  0.00138482\n",
      "  0.76566531  0.34631421 -0.00215674  0.43827275]\n",
      "a_next.shape =  (5, 10)\n",
      "c_next[2] =  [ 0.63267805  1.00570849  0.35504474  0.20690913 -1.64566718  0.11832942\n",
      "  0.76449811 -0.0981561  -0.74348425 -0.26810932]\n",
      "c_next.shape =  (5, 10)\n",
      "yt[1] = [ 0.79913913  0.15986619  0.22412122  0.15606108  0.97057211  0.31146381\n",
      "  0.00943007  0.12666353  0.39380172  0.07828381]\n",
      "yt.shape =  (2, 10)\n",
      "cache[1][3] = [-0.16263996  1.03729328  0.72938082 -0.54101719  0.02752074 -0.30821874\n",
      "  0.07651101 -1.03752894  1.41219977 -0.37647422]\n",
      "len(cache) =  10\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "xt = np.random.randn(3,10)\n",
    "a_prev = np.random.randn(5,10)\n",
    "c_prev = np.random.randn(5,10)\n",
    "Wf = np.random.randn(5, 5+3)\n",
    "bf = np.random.randn(5,1)\n",
    "Wi = np.random.randn(5, 5+3)\n",
    "bi = np.random.randn(5,1)\n",
    "Wo = np.random.randn(5, 5+3)\n",
    "bo = np.random.randn(5,1)\n",
    "Wc = np.random.randn(5, 5+3)\n",
    "bc = np.random.randn(5,1)\n",
    "Wy = np.random.randn(2,5)\n",
    "by = np.random.randn(2,1)\n",
    "\n",
    "parameters = {\"Wf\": Wf, \"Wi\": Wi, \"Wo\": Wo, \"Wc\": Wc, \"Wy\": Wy, \"bf\": bf, \"bi\": bi, \"bo\": bo, \"bc\": bc, \"by\": by}\n",
    "\n",
    "a_next, c_next, yt, cache = lstm_cell_forward(xt, a_prev, c_prev, parameters)\n",
    "print(\"a_next[4] = \", a_next[4])\n",
    "print(\"a_next.shape = \", c_next.shape)\n",
    "print(\"c_next[2] = \", c_next[2])\n",
    "print(\"c_next.shape = \", c_next.shape)\n",
    "print(\"yt[1] =\", yt[1])\n",
    "print(\"yt.shape = \", yt.shape)\n",
    "print(\"cache[1][3] =\", cache[1][3])\n",
    "print(\"len(cache) = \", len(cache))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Expected Output**:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **a_next[4]**:\n",
    "        </td>\n",
    "        <td>\n",
    "           [-0.66408471  0.0036921   0.02088357  0.22834167 -0.85575339  0.00138482\n",
    "  0.76566531  0.34631421 -0.00215674  0.43827275]\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **a_next.shape**:\n",
    "        </td>\n",
    "        <td>\n",
    "           (5, 10)\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **c_next[2]**:\n",
    "        </td>\n",
    "        <td>\n",
    "           [ 0.63267805  1.00570849  0.35504474  0.20690913 -1.64566718  0.11832942\n",
    "  0.76449811 -0.0981561  -0.74348425 -0.26810932]\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **c_next.shape**:\n",
    "        </td>\n",
    "        <td>\n",
    "           (5, 10)\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **yt[1]**:\n",
    "        </td>\n",
    "        <td>\n",
    "           [ 0.79913913  0.15986619  0.22412122  0.15606108  0.97057211  0.31146381\n",
    "  0.00943007  0.12666353  0.39380172  0.07828381]\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **yt.shape**:\n",
    "        </td>\n",
    "        <td>\n",
    "           (2, 10)\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **cache[1][3]**:\n",
    "        </td>\n",
    "        <td>\n",
    "           [-0.16263996  1.03729328  0.72938082 -0.54101719  0.02752074 -0.30821874\n",
    "  0.07651101 -1.03752894  1.41219977 -0.37647422]\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **len(cache)**:\n",
    "        </td>\n",
    "        <td>\n",
    "           10\n",
    "        </td>\n",
    "    </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 - Forward pass for LSTM\n",
    "\n",
    "Now that you have implemented one step of an LSTM, you can now iterate this over this using a for-loop to process a sequence of $T_x$ inputs. \n",
    "\n",
    "<img src=\"images/LSTM_rnn.png\" style=\"width:500;height:300px;\">\n",
    "<caption><center> **Figure 4**: LSTM over multiple time-steps. </center></caption>\n",
    "\n",
    "**Exercise:** Implement `lstm_forward()` to run an LSTM over $T_x$ time-steps. \n",
    "\n",
    "**Note**: $c^{\\langle 0 \\rangle}$ is initialized with zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: lstm_forward\n",
    "\n",
    "def lstm_forward(x, a0, parameters):\n",
    "    \"\"\"\n",
    "    Implement the forward propagation of the recurrent neural network using an LSTM-cell described in Figure (3).\n",
    "\n",
    "    Arguments:\n",
    "    x -- Input data for every time-step, of shape (n_x, m, T_x).\n",
    "    a0 -- Initial hidden state, of shape (n_a, m)\n",
    "    parameters -- python dictionary containing:\n",
    "                        Wf -- Weight matrix of the forget gate, numpy array of shape (n_a, n_a + n_x)\n",
    "                        bf -- Bias of the forget gate, numpy array of shape (n_a, 1)\n",
    "                        Wi -- Weight matrix of the update gate, numpy array of shape (n_a, n_a + n_x)\n",
    "                        bi -- Bias of the update gate, numpy array of shape (n_a, 1)\n",
    "                        Wc -- Weight matrix of the first \"tanh\", numpy array of shape (n_a, n_a + n_x)\n",
    "                        bc -- Bias of the first \"tanh\", numpy array of shape (n_a, 1)\n",
    "                        Wo -- Weight matrix of the output gate, numpy array of shape (n_a, n_a + n_x)\n",
    "                        bo -- Bias of the output gate, numpy array of shape (n_a, 1)\n",
    "                        Wy -- Weight matrix relating the hidden-state to the output, numpy array of shape (n_y, n_a)\n",
    "                        by -- Bias relating the hidden-state to the output, numpy array of shape (n_y, 1)\n",
    "                        \n",
    "    Returns:\n",
    "    a -- Hidden states for every time-step, numpy array of shape (n_a, m, T_x)\n",
    "    y -- Predictions for every time-step, numpy array of shape (n_y, m, T_x)\n",
    "    caches -- tuple of values needed for the backward pass, contains (list of all the caches, x)\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize \"caches\", which will track the list of all the caches\n",
    "    caches = []\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    # Retrieve dimensions from shapes of x and parameters['Wy'] (≈2 lines)\n",
    "    n_x, m, T_x = x.shape\n",
    "    n_y, n_a = parameters['Wy'].shape\n",
    "    \n",
    "    # initialize \"a\", \"c\" and \"y\" with zeros (≈3 lines)\n",
    "    a = np.zeros((n_a, m, T_x))\n",
    "    c = np.zeros((n_a, m, T_x))\n",
    "    y = np.zeros((n_y, m, T_x))\n",
    "    \n",
    "    # Initialize a_next and c_next (≈2 lines)\n",
    "    a_next = a0\n",
    "    c_next = np.zeros((n_a, m))\n",
    "    \n",
    "    # loop over all time-steps\n",
    "    for t in range(T_x):\n",
    "        # Update next hidden state, next memory state, compute the prediction, get the cache (≈1 line)\n",
    "        a_next, c_next, yt, cache = lstm_cell_forward(x[:,:,t], a_next, c_next, parameters)\n",
    "        # Save the value of the new \"next\" hidden state in a (≈1 line)\n",
    "        a[:,:,t] = a_next\n",
    "        # Save the value of the prediction in y (≈1 line)\n",
    "        y[:,:,t] = yt\n",
    "        # Save the value of the next cell state (≈1 line)\n",
    "        c[:,:,t]  = c_next\n",
    "        # Append the cache into caches (≈1 line)\n",
    "        caches.append(cache)\n",
    "        \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # store values needed for backward propagation in cache\n",
    "    caches = (caches, x)\n",
    "\n",
    "    return a, y, c, caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a[4][3][6] =  0.172117767533\n",
      "a.shape =  (5, 10, 7)\n",
      "y[1][4][3] = 0.95087346185\n",
      "y.shape =  (2, 10, 7)\n",
      "caches[1][1[1]] = [ 0.82797464  0.23009474  0.76201118 -0.22232814 -0.20075807  0.18656139\n",
      "  0.41005165]\n",
      "c[1][2][1] -0.855544916718\n",
      "len(caches) =  2\n",
      "([(array([[ -9.33678954e-02,  -9.94427536e-03,  -6.89604887e-01,\n",
      "          8.02285664e-05,   2.64105714e-03,  -7.16370282e-01,\n",
      "          1.09448250e-01,  -4.26364353e-03,   3.91304859e-01,\n",
      "          4.95836794e-02],\n",
      "       [ -4.44388117e-02,  -9.99951099e-02,   7.46237646e-01,\n",
      "          5.39692846e-03,  -1.41244687e-02,   6.66375788e-02,\n",
      "         -9.14219442e-03,   6.27036212e-02,   4.71265675e-04,\n",
      "          1.61618387e-01],\n",
      "       [  3.41927573e-05,   1.01274129e-01,   1.24706965e-04,\n",
      "         -1.18058078e-01,  -2.03633470e-01,   4.49525468e-04,\n",
      "         -6.32216789e-01,  -4.89184968e-02,  -5.63963319e-01,\n",
      "          5.91721790e-02],\n",
      "       [  6.85612578e-01,   1.52796322e-02,   7.53701290e-01,\n",
      "          6.64597075e-01,   1.63649743e-04,  -5.55934368e-01,\n",
      "         -1.26292382e-04,   7.29775370e-02,  -1.23973124e-02,\n",
      "          1.08059007e-01],\n",
      "       [  7.83827844e-04,   1.40913141e-01,   2.53684278e-08,\n",
      "          1.19680515e-01,   5.42610667e-01,   4.76839380e-06,\n",
      "          1.74401804e-02,   1.77309579e-01,   1.22233089e-03,\n",
      "          6.56181909e-03]]), array([[ -5.87508416e-01,  -8.56840552e-02,  -9.93306716e-01,\n",
      "          1.38877923e-02,   4.64374281e-01,  -9.56415783e-01,\n",
      "          7.51425913e-01,  -8.51549100e-02,   7.30137689e-01,\n",
      "          6.83609855e-01],\n",
      "       [ -5.28315585e-02,  -1.13190361e-01,   9.68807534e-01,\n",
      "          5.27767120e-01,  -1.46279880e-02,   7.05335805e-02,\n",
      "         -3.37099380e-02,   8.64202222e-02,   4.82286419e-04,\n",
      "          1.76327513e-01],\n",
      "       [  4.09398576e-02,   8.32240335e-01,   1.08944338e-02,\n",
      "         -3.05338820e-01,  -3.22674838e-01,   6.28012359e-01,\n",
      "         -9.47229382e-01,  -1.36825178e-01,  -7.04835171e-01,\n",
      "          1.18614636e-01],\n",
      "       [  9.94618919e-01,   3.89577154e-02,   9.81508106e-01,\n",
      "          9.98648026e-01,   4.81398360e-03,  -7.15016878e-01,\n",
      "         -2.07747188e-02,   5.39318218e-01,  -4.90135507e-02,\n",
      "          1.09400196e-01],\n",
      "       [  1.42482707e-03,   2.80986507e-01,   7.28084738e-07,\n",
      "          1.59710941e-01,   9.89583833e-01,   3.44850560e-04,\n",
      "          9.87799644e-01,   9.00727739e-01,   7.82101996e-01,\n",
      "          4.67937918e-02]]), array([[ -3.26499498e-01,  -1.34267579e+00,   1.11438298e+00,\n",
      "         -5.86523939e-01,  -1.23685338e+00,   8.75838928e-01,\n",
      "          6.23362177e-01,  -4.34956683e-01,   1.40754000e+00,\n",
      "          1.29101580e-01],\n",
      "       [  1.61694960e+00,   5.02740882e-01,   1.55880554e+00,\n",
      "          1.09402696e-01,  -1.21974440e+00,   2.44936865e+00,\n",
      "         -5.45774168e-01,  -1.98837863e-01,  -7.00398505e-01,\n",
      "         -2.03394449e-01],\n",
      "       [  2.42669441e-01,   2.01830179e-01,   6.61020288e-01,\n",
      "          1.79215821e+00,  -1.20464572e-01,  -1.23312074e+00,\n",
      "         -1.18231813e+00,  -6.65754518e-01,  -1.67419581e+00,\n",
      "          8.25029824e-01],\n",
      "       [ -4.98213564e-01,  -3.10984978e-01,  -1.89148284e-03,\n",
      "         -1.39662042e+00,  -8.61316361e-01,   6.74711526e-01,\n",
      "          6.18539131e-01,  -4.43171931e-01,   1.81053491e+00,\n",
      "         -1.30572692e+00],\n",
      "       [ -3.44987210e-01,  -2.30839743e-01,  -2.79308500e+00,\n",
      "          1.93752881e+00,   3.66332015e-01,  -1.04458938e+00,\n",
      "          2.05117344e+00,   5.85662000e-01,   4.29526140e-01,\n",
      "         -6.06998398e-01]]), array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]]), array([[ 0.80055431,  0.70788964,  0.81651437,  0.99457397,  0.98444372,\n",
      "         0.04845023,  0.82389172,  0.94671056,  0.95085368,  0.9773528 ],\n",
      "       [ 0.32987948,  0.00962202,  0.03138725,  0.69321018,  0.02496498,\n",
      "         0.02251802,  0.22862422,  0.12016487,  0.4860129 ,  0.00400752],\n",
      "       [ 0.53071777,  0.91680268,  0.80656563,  0.00560945,  0.51601423,\n",
      "         0.94342575,  0.12270555,  0.16030774,  0.31997081,  0.30038829],\n",
      "       [ 0.53826589,  0.28878963,  0.93552819,  0.04072249,  0.14096174,\n",
      "         0.71817097,  0.03214311,  0.15257163,  0.1979153 ,  0.33322577],\n",
      "       [ 0.72876762,  0.0887182 ,  0.25856092,  0.63814586,  0.88360999,\n",
      "         0.08692066,  0.51781173,  0.5313078 ,  0.53225234,  0.59233136]]), array([[  5.87514026e-01,   1.08861521e-01,   9.93306774e-01,\n",
      "          1.39321703e-02,   4.66452640e-01,   9.56416558e-01,\n",
      "          7.51436915e-01,   4.63149841e-01,   9.98628559e-01,\n",
      "          8.50998193e-01],\n",
      "       [  9.92896358e-01,   8.77389571e-01,   9.69272158e-01,\n",
      "          5.39909472e-01,   3.57617641e-02,   9.97641918e-01,\n",
      "          4.03022471e-02,   1.04802783e-01,   3.90211103e-03,\n",
      "          1.76444198e-01],\n",
      "       [  4.22468464e-02,   8.62413655e-01,   1.08944338e-02,\n",
      "          3.72627275e-01,   3.34103972e-01,   6.28012688e-01,\n",
      "          9.80419568e-01,   7.35075097e-01,   9.32744707e-01,\n",
      "          1.18615098e-01],\n",
      "       [  9.94667564e-01,   3.97409682e-02,   9.83658118e-01,\n",
      "          9.98650438e-01,   5.03489313e-03,   7.18920090e-01,\n",
      "          2.07751149e-02,   5.73392736e-01,   4.90375142e-02,\n",
      "          1.25473673e-01],\n",
      "       [  1.48838611e-03,   5.28682198e-01,   3.04695189e-06,\n",
      "          2.00317806e-01,   9.93558003e-01,   3.56957403e-04,\n",
      "          9.87839640e-01,   9.14780058e-01,   7.82103632e-01,\n",
      "          5.70608790e-02]]), array([[-0.99999045, -0.78709221, -0.99999994,  0.99681471,  0.99554433,\n",
      "        -0.99999919,  0.99998536, -0.18386039,  0.73114041,  0.80330353],\n",
      "       [-0.05320954, -0.1290081 ,  0.99952065,  0.97751039, -0.40903989,\n",
      "         0.0707003 , -0.83642825,  0.82459854,  0.12359628,  0.99933869],\n",
      "       [ 0.96906304,  0.96501294,  1.        , -0.81942155, -0.96579169,\n",
      "         0.99999948, -0.96614696, -0.18613769, -0.75565711,  0.9999961 ],\n",
      "       [ 0.99995109,  0.98029105,  0.99781427,  0.99999759,  0.95612429,\n",
      "        -0.99457073, -0.99998094,  0.94057386, -0.99951132,  0.87189761],\n",
      "       [ 0.95729667,  0.53148471,  0.23895511,  0.79728779,  0.99600006,\n",
      "         0.96608323,  0.99995951,  0.98463858,  0.99999791,  0.82006784]]), array([[  1.76799226e-01,   1.16341361e-01,   9.08847198e-01,\n",
      "          5.77728428e-03,   6.09039983e-03,   9.64582611e-01,\n",
      "          1.72088751e-01,   5.01902272e-02,   6.27946920e-01,\n",
      "          8.34937221e-02],\n",
      "       [  8.41923856e-01,   8.87193858e-01,   9.97404162e-01,\n",
      "          1.11582308e-02,   9.65647236e-01,   9.46330084e-01,\n",
      "          2.71304477e-01,   7.27371924e-01,   9.77149038e-01,\n",
      "          9.26060273e-01],\n",
      "       [  8.35661391e-04,   1.48566125e-01,   1.14473043e-02,\n",
      "          3.98588024e-01,   6.52831411e-01,   8.07508462e-04,\n",
      "          8.56051988e-01,   3.59753863e-01,   9.28444894e-01,\n",
      "          5.01198061e-01],\n",
      "       [  9.02923796e-01,   3.92409082e-01,   9.99977816e-01,\n",
      "          8.73291149e-01,   3.39949241e-02,   9.05706186e-01,\n",
      "          6.08001253e-03,   1.48186252e-01,   2.53138940e-01,\n",
      "          9.91677937e-01],\n",
      "       [  5.50121758e-01,   5.14623613e-01,   3.48426859e-02,\n",
      "          7.55717641e-01,   7.16615887e-01,   1.38274213e-02,\n",
      "          2.30561358e-02,   2.47413766e-01,   1.86926030e-03,\n",
      "          1.40330747e-01]]), array([[ 1.62434536, -0.7612069 ,  1.13376944,  1.14472371, -0.26788808,\n",
      "        -0.0126646 , -0.74715829,  0.61720311,  0.83898341, -0.29809284],\n",
      "       [-1.44411381,  0.82797464,  0.19829972,  0.18515642, -0.62000084,\n",
      "         0.16938243,  0.84616065,  0.40890054,  1.62765075,  0.5505375 ],\n",
      "       [-0.18656977,  0.61838026,  0.44136444, -0.99702683,  2.19069973,\n",
      "        -0.22631424,  0.50318481, -0.0731127 ,  0.60231928,  1.95487808]]), {'Wf': array([[ 0.10622272, -1.52568032,  0.79502609, -0.37443832,  0.1340482 ,\n",
      "         1.20205486,  0.28474811,  0.26246745],\n",
      "       [ 0.2764993 , -0.7332716 ,  0.83600472,  1.54335911,  0.75880566,\n",
      "         0.88490881, -0.87728152, -0.86778722],\n",
      "       [-1.44087602,  1.23225307, -0.25417987,  1.39984394, -0.78191168,\n",
      "        -0.43750898,  0.09542509,  0.92145007],\n",
      "       [ 0.0607502 ,  0.21112476,  0.01652757,  0.17718772, -1.11647002,\n",
      "         0.0809271 , -0.18657899, -0.05682448],\n",
      "       [ 0.49233656, -0.68067814, -0.08450803, -0.29736188,  0.417302  ,\n",
      "         0.78477065, -0.95542526,  0.58591043]]), 'Wi': array([[ 1.62284909,  0.01335268, -0.6946936 ,  0.6218035 , -0.59980453,\n",
      "         1.12341216,  0.30526704,  1.3887794 ],\n",
      "       [-0.66134424,  3.03085711,  0.82458463,  0.65458015, -0.05118845,\n",
      "        -0.72559712, -0.86776868, -0.13597733],\n",
      "       [-0.79726979,  0.28267571, -0.82609743,  0.6210827 ,  0.9561217 ,\n",
      "        -0.70584051,  1.19268607, -0.23794194],\n",
      "       [ 1.15528789,  0.43816635,  1.12232832, -0.9970198 , -0.10679399,\n",
      "         1.45142926, -0.61803685, -2.03720123],\n",
      "       [-1.94258918, -2.50644065, -2.11416392, -0.41163916,  1.27852808,\n",
      "        -0.44222928,  0.32352735, -0.10999149]]), 'Wo': array([[ 1.01012718,  0.92001793, -0.19505734,  0.80539342, -0.70134443,\n",
      "        -0.53722302,  0.15626385, -0.19022103],\n",
      "       [-0.44873803, -0.67244804, -0.55749472,  0.93916874, -1.94332341,\n",
      "         0.35249436, -0.23643695,  0.7278135 ],\n",
      "       [ 0.51507361, -2.78253447,  0.58464661,  0.32427424,  0.02186284,\n",
      "        -0.46867382,  0.85328122, -0.41302931],\n",
      "       [ 1.83471763,  0.56438286,  2.13782807, -0.785534  , -1.75592564,\n",
      "         0.7147896 ,  0.85270406,  0.0353601 ],\n",
      "       [-1.53879325, -0.44789518,  0.61798553, -0.18417633, -0.11598519,\n",
      "        -0.17545897, -0.93391466, -0.53302033]]), 'Wc': array([[ 0.79452824, -1.87316098,  0.92061512, -0.03536792,  2.11060505,\n",
      "        -1.30653407,  0.07638048,  0.36723181],\n",
      "       [ 1.23289919, -0.42285696,  0.08646441, -2.14246673, -0.83016886,\n",
      "         0.45161595,  1.10417433, -0.28173627],\n",
      "       [ 2.05635552,  1.76024923, -0.06065249, -2.413503  , -1.77756638,\n",
      "        -0.77785883,  1.11584111,  0.31027229],\n",
      "       [-2.09424782, -0.22876583,  1.61336137, -0.37480469, -0.74996962,\n",
      "         2.0546241 ,  0.05340954, -0.4791571 ],\n",
      "       [ 0.35016716,  0.01716473, -0.42914228,  1.20845633,  1.1157018 ,\n",
      "         0.84086156, -0.10288722,  1.14690038]]), 'Wy': array([[ 0.45128402, -1.68405999, -1.1601701 ,  1.35010682, -0.33128317],\n",
      "       [ 0.38653915, -0.85145566,  1.00088142, -0.38483225,  1.45810824]]), 'bf': array([[ 2.06578332],\n",
      "       [-1.47115693],\n",
      "       [-0.8301719 ],\n",
      "       [-0.8805776 ],\n",
      "       [-0.27909772]]), 'bi': array([[ 0.00854895],\n",
      "       [-0.16819884],\n",
      "       [-0.17418034],\n",
      "       [ 0.4611641 ],\n",
      "       [-1.17598267]]), 'bo': array([[-1.42655542],\n",
      "       [ 1.76795995],\n",
      "       [-0.47537288],\n",
      "       [ 0.47761018],\n",
      "       [-1.02188594]]), 'bc': array([[-0.04970258],\n",
      "       [ 0.46664327],\n",
      "       [ 1.03368687],\n",
      "       [ 0.80884436],\n",
      "       [ 1.78975468]]), 'by': array([[-0.53223402],\n",
      "       [ 1.1181334 ]])}), (array([[-0.0739075 ,  0.00701457, -0.16593734, -0.10077244,  0.06101538,\n",
      "        -0.0485158 , -0.0170545 ,  0.01158212, -0.02129439,  0.09432164],\n",
      "       [-0.57199847,  0.13163265, -0.59506418, -0.04552514,  0.07809638,\n",
      "         0.26759693, -0.01239869, -0.02582314,  0.10759044,  0.27244006],\n",
      "       [-0.1604868 ,  0.20576596,  0.00822248, -0.09999123, -0.09030859,\n",
      "         0.30413827, -0.02197245,  0.03781878,  0.06197299,  0.28819073],\n",
      "       [ 0.04322923,  0.33599147,  0.04412853,  0.3400432 ,  0.37084725,\n",
      "        -0.05887205,  0.22337146,  0.12827567,  0.28493593,  0.63602438],\n",
      "       [ 0.1016255 ,  0.08010747,  0.06955194,  0.06369949,  0.1341287 ,\n",
      "         0.14259782,  0.12046839,  0.09873775,  0.04137763,  0.02353377]]), array([[-0.23309138,  0.05011365, -0.38706543, -0.64700801,  0.37806849,\n",
      "        -0.46548146, -0.22937671,  0.08290081, -0.11338143,  0.37887998],\n",
      "       [-0.73923067,  0.15573133, -0.85554492, -0.04830539,  0.21298927,\n",
      "         0.31693896, -0.01268108, -0.02809238,  0.11744329,  0.43157468],\n",
      "       [-0.3915011 ,  0.48866472,  0.06934047, -0.45697277, -0.14138088,\n",
      "         1.29575587, -0.4140796 ,  0.17760726,  0.22271767,  0.59270382],\n",
      "       [ 0.17889411,  0.53356729,  0.28021308,  0.95786677,  0.9596407 ,\n",
      "        -0.1553998 ,  0.53932726,  0.23053873,  0.41574857,  0.98679547],\n",
      "       [ 0.25127928,  0.39765339,  0.16476908,  0.27660472,  0.5208895 ,\n",
      "         0.6196775 ,  1.16422847,  0.81118603,  0.75998902,  0.10782036]]), array([[ -9.33678954e-02,  -9.94427536e-03,  -6.89604887e-01,\n",
      "          8.02285664e-05,   2.64105714e-03,  -7.16370282e-01,\n",
      "          1.09448250e-01,  -4.26364353e-03,   3.91304859e-01,\n",
      "          4.95836794e-02],\n",
      "       [ -4.44388117e-02,  -9.99951099e-02,   7.46237646e-01,\n",
      "          5.39692846e-03,  -1.41244687e-02,   6.66375788e-02,\n",
      "         -9.14219442e-03,   6.27036212e-02,   4.71265675e-04,\n",
      "          1.61618387e-01],\n",
      "       [  3.41927573e-05,   1.01274129e-01,   1.24706965e-04,\n",
      "         -1.18058078e-01,  -2.03633470e-01,   4.49525468e-04,\n",
      "         -6.32216789e-01,  -4.89184968e-02,  -5.63963319e-01,\n",
      "          5.91721790e-02],\n",
      "       [  6.85612578e-01,   1.52796322e-02,   7.53701290e-01,\n",
      "          6.64597075e-01,   1.63649743e-04,  -5.55934368e-01,\n",
      "         -1.26292382e-04,   7.29775370e-02,  -1.23973124e-02,\n",
      "          1.08059007e-01],\n",
      "       [  7.83827844e-04,   1.40913141e-01,   2.53684278e-08,\n",
      "          1.19680515e-01,   5.42610667e-01,   4.76839380e-06,\n",
      "          1.74401804e-02,   1.77309579e-01,   1.22233089e-03,\n",
      "          6.56181909e-03]]), array([[ -5.87508416e-01,  -8.56840552e-02,  -9.93306716e-01,\n",
      "          1.38877923e-02,   4.64374281e-01,  -9.56415783e-01,\n",
      "          7.51425913e-01,  -8.51549100e-02,   7.30137689e-01,\n",
      "          6.83609855e-01],\n",
      "       [ -5.28315585e-02,  -1.13190361e-01,   9.68807534e-01,\n",
      "          5.27767120e-01,  -1.46279880e-02,   7.05335805e-02,\n",
      "         -3.37099380e-02,   8.64202222e-02,   4.82286419e-04,\n",
      "          1.76327513e-01],\n",
      "       [  4.09398576e-02,   8.32240335e-01,   1.08944338e-02,\n",
      "         -3.05338820e-01,  -3.22674838e-01,   6.28012359e-01,\n",
      "         -9.47229382e-01,  -1.36825178e-01,  -7.04835171e-01,\n",
      "          1.18614636e-01],\n",
      "       [  9.94618919e-01,   3.89577154e-02,   9.81508106e-01,\n",
      "          9.98648026e-01,   4.81398360e-03,  -7.15016878e-01,\n",
      "         -2.07747188e-02,   5.39318218e-01,  -4.90135507e-02,\n",
      "          1.09400196e-01],\n",
      "       [  1.42482707e-03,   2.80986507e-01,   7.28084738e-07,\n",
      "          1.59710941e-01,   9.89583833e-01,   3.44850560e-04,\n",
      "          9.87799644e-01,   9.00727739e-01,   7.82101996e-01,\n",
      "          4.67937918e-02]]), array([[ 0.72339444,  0.94380092,  0.32242851,  0.94120435,  0.91189059,\n",
      "         0.78814999,  0.97634453,  0.92992764,  0.95206852,  0.90848835],\n",
      "       [ 0.39744704,  0.21303911,  0.11542512,  0.61156332,  0.57059126,\n",
      "         0.0046347 ,  0.30571532,  0.11591006,  0.15573699,  0.3864863 ],\n",
      "       [ 0.58285032,  0.27748113,  0.92678559,  0.46061025,  0.04162674,\n",
      "         0.78451529,  0.38152136,  0.54108387,  0.22162588,  0.12600304],\n",
      "       [ 0.32637478,  0.25245517,  0.32368293,  0.31682527,  0.18662325,\n",
      "         0.21202146,  0.33582502,  0.25152646,  0.2929322 ,  0.29664108],\n",
      "       [ 0.3644523 ,  0.49913182,  0.0842277 ,  0.68813933,  0.19998336,\n",
      "         0.21146152,  0.93984892,  0.66183583,  0.65001282,  0.17456862]]), array([[ 0.33174616,  0.64502419,  0.12234171,  0.84238108,  0.1196254 ,\n",
      "         0.33645069,  0.98287008,  0.87176233,  0.94046434,  0.27976269],\n",
      "       [ 0.75084457,  0.30128795,  0.97705611,  0.45445167,  0.24213154,\n",
      "         0.53271366,  0.19021547,  0.41794916,  0.12732275,  0.38858032],\n",
      "       [ 0.54204628,  0.46504694,  0.88044919,  0.33377318,  0.80475087,\n",
      "         0.80615757,  0.09512512,  0.39768602,  0.4059495 ,  0.68442013],\n",
      "       [ 0.32768928,  0.58333002,  0.09745773,  0.66583458,  0.98754383,\n",
      "         0.01020819,  0.55612262,  0.17138569,  0.64084737,  0.97010623],\n",
      "       [ 0.25999398,  0.26144135,  0.18522243,  0.16684961,  0.54447128,\n",
      "         0.70344481,  0.23586311,  0.21532481,  0.25219049,  0.16089002]]), array([[ 0.57848126,  0.20306577, -0.545971  , -0.78358747, -0.37943489,\n",
      "         0.85693872, -0.97981137,  0.18593223, -0.85970568, -0.86563226],\n",
      "       [-0.95656672,  0.59692168, -0.99008606, -0.81651895,  0.91411416,\n",
      "         0.59433816, -0.01248813, -0.09118178,  0.9218163 ,  0.93526743],\n",
      "       [-0.76628681,  0.55421016,  0.067288  , -0.94774113, -0.15899203,\n",
      "         0.99617072, -0.55391643,  0.6327634 ,  0.93343478,  0.84415696],\n",
      "       [-0.44470306,  0.89783175, -0.38462143,  0.96340722,  0.97083518,\n",
      "        -0.37233552,  0.98234439,  0.55363973,  0.67115235,  0.9837509 ],\n",
      "       [ 0.96448384,  0.98455765,  0.88957377,  0.99911139,  0.59321623,\n",
      "         0.88081476,  0.99992761,  0.99873367,  0.99770889,  0.61937737]]), array([[ 0.32279691,  0.14009038,  0.44990488,  0.17690165,  0.16900414,\n",
      "         0.11164832,  0.07565093,  0.14003043,  0.18861604,  0.26074832],\n",
      "       [ 0.90984023,  0.85207683,  0.85749657,  0.94317732,  0.37219603,\n",
      "         0.87240005,  0.97778388,  0.91946405,  0.92031353,  0.66998435],\n",
      "       [ 0.43065946,  0.45407313,  0.11877122,  0.2338354 ,  0.64301133,\n",
      "         0.35339168,  0.05606203,  0.21516915,  0.28284377,  0.54187749],\n",
      "       [ 0.24421938,  0.68836151,  0.16158242,  0.45746307,  0.49837253,\n",
      "         0.38188718,  0.45356585,  0.56623976,  0.72439595,  0.84131034],\n",
      "       [ 0.41290898,  0.21195856,  0.42593079,  0.23613415,  0.28037742,\n",
      "         0.25884358,  0.1464816 ,  0.14731612,  0.06454459,  0.21911349]]), array([[-0.61175641,  0.3190391 , -1.09989127,  0.90159072,  0.53035547,\n",
      "        -1.11731035,  1.6924546 ,  0.30017032,  0.93110208,  0.48851815],\n",
      "       [-0.50446586,  0.23009474,  0.11900865, -0.37528495,  0.69803203,\n",
      "         0.74055645, -0.85951594, -0.02461696,  0.3380117 ,  0.79280687],\n",
      "       [-0.10174587,  0.23249456, -0.10015523,  0.24879916, -1.89636092,\n",
      "         1.33145711,  1.29322588,  1.16033857,  0.4202822 , -1.33195167]]), {'Wf': array([[ 0.10622272, -1.52568032,  0.79502609, -0.37443832,  0.1340482 ,\n",
      "         1.20205486,  0.28474811,  0.26246745],\n",
      "       [ 0.2764993 , -0.7332716 ,  0.83600472,  1.54335911,  0.75880566,\n",
      "         0.88490881, -0.87728152, -0.86778722],\n",
      "       [-1.44087602,  1.23225307, -0.25417987,  1.39984394, -0.78191168,\n",
      "        -0.43750898,  0.09542509,  0.92145007],\n",
      "       [ 0.0607502 ,  0.21112476,  0.01652757,  0.17718772, -1.11647002,\n",
      "         0.0809271 , -0.18657899, -0.05682448],\n",
      "       [ 0.49233656, -0.68067814, -0.08450803, -0.29736188,  0.417302  ,\n",
      "         0.78477065, -0.95542526,  0.58591043]]), 'Wi': array([[ 1.62284909,  0.01335268, -0.6946936 ,  0.6218035 , -0.59980453,\n",
      "         1.12341216,  0.30526704,  1.3887794 ],\n",
      "       [-0.66134424,  3.03085711,  0.82458463,  0.65458015, -0.05118845,\n",
      "        -0.72559712, -0.86776868, -0.13597733],\n",
      "       [-0.79726979,  0.28267571, -0.82609743,  0.6210827 ,  0.9561217 ,\n",
      "        -0.70584051,  1.19268607, -0.23794194],\n",
      "       [ 1.15528789,  0.43816635,  1.12232832, -0.9970198 , -0.10679399,\n",
      "         1.45142926, -0.61803685, -2.03720123],\n",
      "       [-1.94258918, -2.50644065, -2.11416392, -0.41163916,  1.27852808,\n",
      "        -0.44222928,  0.32352735, -0.10999149]]), 'Wo': array([[ 1.01012718,  0.92001793, -0.19505734,  0.80539342, -0.70134443,\n",
      "        -0.53722302,  0.15626385, -0.19022103],\n",
      "       [-0.44873803, -0.67244804, -0.55749472,  0.93916874, -1.94332341,\n",
      "         0.35249436, -0.23643695,  0.7278135 ],\n",
      "       [ 0.51507361, -2.78253447,  0.58464661,  0.32427424,  0.02186284,\n",
      "        -0.46867382,  0.85328122, -0.41302931],\n",
      "       [ 1.83471763,  0.56438286,  2.13782807, -0.785534  , -1.75592564,\n",
      "         0.7147896 ,  0.85270406,  0.0353601 ],\n",
      "       [-1.53879325, -0.44789518,  0.61798553, -0.18417633, -0.11598519,\n",
      "        -0.17545897, -0.93391466, -0.53302033]]), 'Wc': array([[ 0.79452824, -1.87316098,  0.92061512, -0.03536792,  2.11060505,\n",
      "        -1.30653407,  0.07638048,  0.36723181],\n",
      "       [ 1.23289919, -0.42285696,  0.08646441, -2.14246673, -0.83016886,\n",
      "         0.45161595,  1.10417433, -0.28173627],\n",
      "       [ 2.05635552,  1.76024923, -0.06065249, -2.413503  , -1.77756638,\n",
      "        -0.77785883,  1.11584111,  0.31027229],\n",
      "       [-2.09424782, -0.22876583,  1.61336137, -0.37480469, -0.74996962,\n",
      "         2.0546241 ,  0.05340954, -0.4791571 ],\n",
      "       [ 0.35016716,  0.01716473, -0.42914228,  1.20845633,  1.1157018 ,\n",
      "         0.84086156, -0.10288722,  1.14690038]]), 'Wy': array([[ 0.45128402, -1.68405999, -1.1601701 ,  1.35010682, -0.33128317],\n",
      "       [ 0.38653915, -0.85145566,  1.00088142, -0.38483225,  1.45810824]]), 'bf': array([[ 2.06578332],\n",
      "       [-1.47115693],\n",
      "       [-0.8301719 ],\n",
      "       [-0.8805776 ],\n",
      "       [-0.27909772]]), 'bi': array([[ 0.00854895],\n",
      "       [-0.16819884],\n",
      "       [-0.17418034],\n",
      "       [ 0.4611641 ],\n",
      "       [-1.17598267]]), 'bo': array([[-1.42655542],\n",
      "       [ 1.76795995],\n",
      "       [-0.47537288],\n",
      "       [ 0.47761018],\n",
      "       [-1.02188594]]), 'bc': array([[-0.04970258],\n",
      "       [ 0.46664327],\n",
      "       [ 1.03368687],\n",
      "       [ 0.80884436],\n",
      "       [ 1.78975468]]), 'by': array([[-0.53223402],\n",
      "       [ 1.1181334 ]])}), (array([[ 0.05155047,  0.11874537, -0.01175475, -0.11949823,  0.11705735,\n",
      "        -0.07921719, -0.03177438,  0.07089184, -0.05008804,  0.08695071],\n",
      "       [-0.04045431,  0.0948033 , -0.37165796, -0.33261676, -0.36436271,\n",
      "        -0.19451941,  0.09842137, -0.41887032, -0.54482437, -0.23474078],\n",
      "       [ 0.06556925,  0.3482001 , -0.16548848, -0.1042375 , -0.01710391,\n",
      "         0.03802179,  0.08198868,  0.02383698,  0.00204635, -0.08222757],\n",
      "       [ 0.00061476,  0.11221511,  0.12644806,  0.29829221, -0.04808597,\n",
      "         0.39362617,  0.27884288, -0.00546722,  0.1684102 ,  0.47216029],\n",
      "       [ 0.15010745,  0.02866651,  0.33194367,  0.16568685,  0.1417647 ,\n",
      "         0.22390536,  0.12292504,  0.23612537,  0.24235846,  0.0292006 ]]), array([[ 0.41473874,  0.47447822, -0.1124046 , -0.93384064,  0.35455569,\n",
      "        -0.54181388, -0.1503047 ,  0.3797108 , -0.32321358,  0.21521843],\n",
      "       [-0.0437153 ,  0.10871546, -0.44195677, -0.38749851, -0.51295426,\n",
      "        -0.25830363,  0.11832139, -0.51609037, -0.65780941, -0.35764218],\n",
      "       [ 0.08931322,  0.95385785, -0.25465243, -0.41076218, -0.04216542,\n",
      "         0.29771742,  0.17127168,  0.0876137 ,  0.01958639, -0.23307712],\n",
      "       [ 0.00191185,  0.15086247,  0.51110419,  1.10101429, -0.17870374,\n",
      "         0.82292012,  0.52035814, -0.01551753,  0.46448495,  1.24437898],\n",
      "       [ 0.85922622,  0.26101562,  0.69129965,  0.41414717,  0.37077226,\n",
      "         0.45123993,  0.67859102,  0.70389563,  0.71006197,  0.05080657]]), array([[-0.0739075 ,  0.00701457, -0.16593734, -0.10077244,  0.06101538,\n",
      "        -0.0485158 , -0.0170545 ,  0.01158212, -0.02129439,  0.09432164],\n",
      "       [-0.57199847,  0.13163265, -0.59506418, -0.04552514,  0.07809638,\n",
      "         0.26759693, -0.01239869, -0.02582314,  0.10759044,  0.27244006],\n",
      "       [-0.1604868 ,  0.20576596,  0.00822248, -0.09999123, -0.09030859,\n",
      "         0.30413827, -0.02197245,  0.03781878,  0.06197299,  0.28819073],\n",
      "       [ 0.04322923,  0.33599147,  0.04412853,  0.3400432 ,  0.37084725,\n",
      "        -0.05887205,  0.22337146,  0.12827567,  0.28493593,  0.63602438],\n",
      "       [ 0.1016255 ,  0.08010747,  0.06955194,  0.06369949,  0.1341287 ,\n",
      "         0.14259782,  0.12046839,  0.09873775,  0.04137763,  0.02353377]]), array([[-0.23309138,  0.05011365, -0.38706543, -0.64700801,  0.37806849,\n",
      "        -0.46548146, -0.22937671,  0.08290081, -0.11338143,  0.37887998],\n",
      "       [-0.73923067,  0.15573133, -0.85554492, -0.04830539,  0.21298927,\n",
      "         0.31693896, -0.01268108, -0.02809238,  0.11744329,  0.43157468],\n",
      "       [-0.3915011 ,  0.48866472,  0.06934047, -0.45697277, -0.14138088,\n",
      "         1.29575587, -0.4140796 ,  0.17760726,  0.22271767,  0.59270382],\n",
      "       [ 0.17889411,  0.53356729,  0.28021308,  0.95786677,  0.9596407 ,\n",
      "        -0.1553998 ,  0.53932726,  0.23053873,  0.41574857,  0.98679547],\n",
      "       [ 0.25127928,  0.39765339,  0.16476908,  0.27660472,  0.5208895 ,\n",
      "         0.6196775 ,  1.16422847,  0.81118603,  0.75998902,  0.10782036]]), array([[ 0.91976789,  0.88190453,  0.92562308,  0.90640791,  0.65292226,\n",
      "         0.8664729 ,  0.89376901,  0.8255646 ,  0.88716949,  0.71580638],\n",
      "       [ 0.08133932,  0.09146684,  0.40161106,  0.57110048,  0.36092874,\n",
      "         0.47109081,  0.22869084,  0.25033633,  0.39367483,  0.83251978],\n",
      "       [ 0.41103314,  0.61965322,  0.1925799 ,  0.30077908,  0.32721513,\n",
      "         0.23865971,  0.33462246,  0.40967229,  0.5477821 ,  0.18535114],\n",
      "       [ 0.22508729,  0.25350498,  0.27546728,  0.32472635,  0.29282457,\n",
      "         0.31466432,  0.26220645,  0.29378249,  0.34230174,  0.37381789],\n",
      "       [ 0.51466337,  0.27429411,  0.61891991,  0.6146709 ,  0.30079388,\n",
      "         0.62081169,  0.34228939,  0.60460935,  0.8036967 ,  0.24657893]]), array([[ 0.65034931,  0.71910011,  0.29388095,  0.51116176,  0.18385451,\n",
      "         0.3043163 ,  0.51831878,  0.47553391,  0.76236683,  0.08517454],\n",
      "       [ 0.13752621,  0.5096257 ,  0.24894263,  0.53179158,  0.76267501,\n",
      "         0.82870177,  0.40164651,  0.67567854,  0.75596207,  0.88926346],\n",
      "       [ 0.58335985,  0.70995654,  0.31676136,  0.31047345,  0.58449912,\n",
      "         0.1906347 ,  0.62632594,  0.30753028,  0.14352161,  0.43430454],\n",
      "       [ 0.06039622,  0.14075271,  0.60078026,  0.83133964,  0.66168144,\n",
      "         0.91850017,  0.5641184 ,  0.39707174,  0.44235342,  0.98578113],\n",
      "       [ 0.73932831,  0.15333064,  0.63772807,  0.24796611,  0.25958521,\n",
      "         0.07112645,  0.28901797,  0.21824398,  0.09946495,  0.0542836 ]]), array([[ 0.96737046,  0.59836282,  0.83663844, -0.67960377,  0.58582385,\n",
      "        -0.4550752 ,  0.10554332,  0.65457125, -0.29201826, -0.65731232],\n",
      "       [ 0.11934616,  0.18537372, -0.39511298, -0.67679009, -0.7733677 ,\n",
      "        -0.49186653,  0.30181126, -0.75340239, -0.9313217 , -0.80621399],\n",
      "       [ 0.42895161,  0.91703526, -0.84608176, -0.88031466,  0.00700864,\n",
      "        -0.060468  ,  0.49468177,  0.04829743, -0.71358146, -0.78961976],\n",
      "       [-0.63505525,  0.11083626,  0.72225185,  0.95023701, -0.69476047,\n",
      "         0.94917662,  0.67174382, -0.2096492 ,  0.72831695,  0.88812533],\n",
      "       [ 0.98725014,  0.99094107,  0.92409417,  0.98451475,  0.82474612,\n",
      "         0.93547333,  0.96910223,  0.97801077,  0.99795261,  0.44618157]]), array([[ 0.13134251,  0.26876991,  0.10501544,  0.16316436,  0.34387209,\n",
      "         0.16024198,  0.21298932,  0.19558729,  0.16032802,  0.41023005],\n",
      "       [ 0.92599348,  0.87546425,  0.89498966,  0.90090796,  0.77155633,\n",
      "         0.76973927,  0.83569194,  0.88243246,  0.9443939 ,  0.68410517],\n",
      "       [ 0.73610046,  0.46957323,  0.66384718,  0.26788034,  0.40587877,\n",
      "         0.13146215,  0.48337707,  0.2727649 ,  0.10449132,  0.3591567 ],\n",
      "       [ 0.32155019,  0.74945837,  0.26857838,  0.37246344,  0.27194035,\n",
      "         0.58172263,  0.58338214,  0.35235404,  0.38828126,  0.55764775],\n",
      "       [ 0.21571539,  0.11230967,  0.55433308,  0.42268314,  0.39971209,\n",
      "         0.52943011,  0.20813493,  0.38910989,  0.39684334,  0.57523498]]), array([[-0.52817175, -0.24937038, -0.17242821,  0.50249434, -0.69166075,\n",
      "         0.2344157 ,  0.05080775, -0.35224985,  0.28558733, -0.07557171],\n",
      "       [ 0.16003707,  0.76201118, -0.67066229, -0.63873041, -0.44712856,\n",
      "        -0.9537006 ,  0.35054598, -0.77516162, -1.19926803, -0.62353073],\n",
      "       [ 0.86888616,  0.68255141, -0.13644474, -0.29664115, -0.64691669,\n",
      "        -0.28730786, -0.11044703,  0.36949272,  0.81095167, -1.76068856]]), {'Wf': array([[ 0.10622272, -1.52568032,  0.79502609, -0.37443832,  0.1340482 ,\n",
      "         1.20205486,  0.28474811,  0.26246745],\n",
      "       [ 0.2764993 , -0.7332716 ,  0.83600472,  1.54335911,  0.75880566,\n",
      "         0.88490881, -0.87728152, -0.86778722],\n",
      "       [-1.44087602,  1.23225307, -0.25417987,  1.39984394, -0.78191168,\n",
      "        -0.43750898,  0.09542509,  0.92145007],\n",
      "       [ 0.0607502 ,  0.21112476,  0.01652757,  0.17718772, -1.11647002,\n",
      "         0.0809271 , -0.18657899, -0.05682448],\n",
      "       [ 0.49233656, -0.68067814, -0.08450803, -0.29736188,  0.417302  ,\n",
      "         0.78477065, -0.95542526,  0.58591043]]), 'Wi': array([[ 1.62284909,  0.01335268, -0.6946936 ,  0.6218035 , -0.59980453,\n",
      "         1.12341216,  0.30526704,  1.3887794 ],\n",
      "       [-0.66134424,  3.03085711,  0.82458463,  0.65458015, -0.05118845,\n",
      "        -0.72559712, -0.86776868, -0.13597733],\n",
      "       [-0.79726979,  0.28267571, -0.82609743,  0.6210827 ,  0.9561217 ,\n",
      "        -0.70584051,  1.19268607, -0.23794194],\n",
      "       [ 1.15528789,  0.43816635,  1.12232832, -0.9970198 , -0.10679399,\n",
      "         1.45142926, -0.61803685, -2.03720123],\n",
      "       [-1.94258918, -2.50644065, -2.11416392, -0.41163916,  1.27852808,\n",
      "        -0.44222928,  0.32352735, -0.10999149]]), 'Wo': array([[ 1.01012718,  0.92001793, -0.19505734,  0.80539342, -0.70134443,\n",
      "        -0.53722302,  0.15626385, -0.19022103],\n",
      "       [-0.44873803, -0.67244804, -0.55749472,  0.93916874, -1.94332341,\n",
      "         0.35249436, -0.23643695,  0.7278135 ],\n",
      "       [ 0.51507361, -2.78253447,  0.58464661,  0.32427424,  0.02186284,\n",
      "        -0.46867382,  0.85328122, -0.41302931],\n",
      "       [ 1.83471763,  0.56438286,  2.13782807, -0.785534  , -1.75592564,\n",
      "         0.7147896 ,  0.85270406,  0.0353601 ],\n",
      "       [-1.53879325, -0.44789518,  0.61798553, -0.18417633, -0.11598519,\n",
      "        -0.17545897, -0.93391466, -0.53302033]]), 'Wc': array([[ 0.79452824, -1.87316098,  0.92061512, -0.03536792,  2.11060505,\n",
      "        -1.30653407,  0.07638048,  0.36723181],\n",
      "       [ 1.23289919, -0.42285696,  0.08646441, -2.14246673, -0.83016886,\n",
      "         0.45161595,  1.10417433, -0.28173627],\n",
      "       [ 2.05635552,  1.76024923, -0.06065249, -2.413503  , -1.77756638,\n",
      "        -0.77785883,  1.11584111,  0.31027229],\n",
      "       [-2.09424782, -0.22876583,  1.61336137, -0.37480469, -0.74996962,\n",
      "         2.0546241 ,  0.05340954, -0.4791571 ],\n",
      "       [ 0.35016716,  0.01716473, -0.42914228,  1.20845633,  1.1157018 ,\n",
      "         0.84086156, -0.10288722,  1.14690038]]), 'Wy': array([[ 0.45128402, -1.68405999, -1.1601701 ,  1.35010682, -0.33128317],\n",
      "       [ 0.38653915, -0.85145566,  1.00088142, -0.38483225,  1.45810824]]), 'bf': array([[ 2.06578332],\n",
      "       [-1.47115693],\n",
      "       [-0.8301719 ],\n",
      "       [-0.8805776 ],\n",
      "       [-0.27909772]]), 'bi': array([[ 0.00854895],\n",
      "       [-0.16819884],\n",
      "       [-0.17418034],\n",
      "       [ 0.4611641 ],\n",
      "       [-1.17598267]]), 'bo': array([[-1.42655542],\n",
      "       [ 1.76795995],\n",
      "       [-0.47537288],\n",
      "       [ 0.47761018],\n",
      "       [-1.02188594]]), 'bc': array([[-0.04970258],\n",
      "       [ 0.46664327],\n",
      "       [ 1.03368687],\n",
      "       [ 0.80884436],\n",
      "       [ 1.78975468]]), 'by': array([[-0.53223402],\n",
      "       [ 1.1181334 ]])}), (array([[ 0.18896522, -0.03046246,  0.03342131, -0.07887489,  0.13965167,\n",
      "        -0.06006673, -0.00909386,  0.15590361,  0.01843266, -0.03303514],\n",
      "       [ 0.19407407,  0.28652419, -0.02310186, -0.07463511,  0.05856306,\n",
      "        -0.20638714, -0.51780505,  0.07190293, -0.08121199, -0.12945372],\n",
      "       [ 0.45623508,  0.01845876,  0.24420065, -0.24790231,  0.51500989,\n",
      "        -0.0239799 , -0.03726765,  0.59522601, -0.09871058, -0.32759264],\n",
      "       [-0.02531204,  0.69611559, -0.02161839,  0.35662858, -0.05146256,\n",
      "         0.48279425, -0.01202097, -0.00293715,  0.19893847,  0.6606636 ],\n",
      "       [ 0.0541676 ,  0.06251229,  0.16681163,  0.10030457,  0.039482  ,\n",
      "         0.11320029,  0.28992853,  0.03469357,  0.07207054,  0.07290125]]), array([[ 0.83253374, -0.25617166,  0.16062589, -1.11478728,  1.08367512,\n",
      "        -1.31385664, -0.03360834,  1.18881672,  0.26083247, -0.16740437],\n",
      "       [ 0.24656518,  0.34466275, -0.03077283, -0.08013564,  0.06763736,\n",
      "        -0.22025283, -0.78363658,  0.07985922, -0.08682834, -0.16300634],\n",
      "       [ 0.85821926,  0.07895222,  0.32234279, -0.49553482,  0.75424409,\n",
      "        -0.09676153, -0.16124708,  0.90323788, -0.1371189 , -0.494319  ],\n",
      "       [-0.04176625,  1.02846153, -0.08674426,  0.70761015, -0.06992232,\n",
      "         0.97708522, -0.05991712, -0.00500959,  0.28484996,  1.37726539],\n",
      "       [ 0.53888703,  0.22624343,  0.84145756,  0.72508539,  0.6582262 ,\n",
      "         0.58409777,  0.47678882,  0.87473807,  1.03157393,  0.27728315]]), array([[ 0.05155047,  0.11874537, -0.01175475, -0.11949823,  0.11705735,\n",
      "        -0.07921719, -0.03177438,  0.07089184, -0.05008804,  0.08695071],\n",
      "       [-0.04045431,  0.0948033 , -0.37165796, -0.33261676, -0.36436271,\n",
      "        -0.19451941,  0.09842137, -0.41887032, -0.54482437, -0.23474078],\n",
      "       [ 0.06556925,  0.3482001 , -0.16548848, -0.1042375 , -0.01710391,\n",
      "         0.03802179,  0.08198868,  0.02383698,  0.00204635, -0.08222757],\n",
      "       [ 0.00061476,  0.11221511,  0.12644806,  0.29829221, -0.04808597,\n",
      "         0.39362617,  0.27884288, -0.00546722,  0.1684102 ,  0.47216029],\n",
      "       [ 0.15010745,  0.02866651,  0.33194367,  0.16568685,  0.1417647 ,\n",
      "         0.22390536,  0.12292504,  0.23612537,  0.24235846,  0.0292006 ]]), array([[ 0.41473874,  0.47447822, -0.1124046 , -0.93384064,  0.35455569,\n",
      "        -0.54181388, -0.1503047 ,  0.3797108 , -0.32321358,  0.21521843],\n",
      "       [-0.0437153 ,  0.10871546, -0.44195677, -0.38749851, -0.51295426,\n",
      "        -0.25830363,  0.11832139, -0.51609037, -0.65780941, -0.35764218],\n",
      "       [ 0.08931322,  0.95385785, -0.25465243, -0.41076218, -0.04216542,\n",
      "         0.29771742,  0.17127168,  0.0876137 ,  0.01958639, -0.23307712],\n",
      "       [ 0.00191185,  0.15086247,  0.51110419,  1.10101429, -0.17870374,\n",
      "         0.82292012,  0.52035814, -0.01551753,  0.46448495,  1.24437898],\n",
      "       [ 0.85922622,  0.26101562,  0.69129965,  0.41414717,  0.37077226,\n",
      "         0.45123993,  0.67859102,  0.70389563,  0.71006197,  0.05080657]]), array([[ 0.79603246,  0.97780062,  0.8202698 ,  0.97637745,  0.94080488,\n",
      "         0.98744325,  0.64292651,  0.90501797,  0.98841856,  0.96339076],\n",
      "       [ 0.02590947,  0.67616191,  0.13034235,  0.31746785,  0.03356331,\n",
      "         0.63897888,  0.54074931,  0.00870554,  0.17939497,  0.79968281],\n",
      "       [ 0.53917765,  0.14369394,  0.26868725,  0.34281813,  0.37741617,\n",
      "         0.32863127,  0.30892911,  0.67472722,  0.32604917,  0.07228035],\n",
      "       [ 0.20663436,  0.33575093,  0.19070806,  0.24486937,  0.19321193,\n",
      "         0.27673441,  0.32742984,  0.15879057,  0.19970193,  0.3128342 ],\n",
      "       [ 0.196433  ,  0.69891563,  0.26184384,  0.61543609,  0.29908792,\n",
      "         0.85104939,  0.49797266,  0.29763899,  0.6455871 ,  0.31556025]]), array([[ 0.51517027,  0.76082472,  0.25782948,  0.857874  ,  0.78085426,\n",
      "         0.93639114,  0.122111  ,  0.84643147,  0.92997767,  0.40550839],\n",
      "       [ 0.41049375,  0.39506006,  0.26269162,  0.11056802,  0.09111718,\n",
      "         0.18337833,  0.88893053,  0.11753978,  0.03840893,  0.1485794 ],\n",
      "       [ 0.81559832,  0.16030097,  0.7959265 ,  0.50206604,  0.78164897,\n",
      "         0.19944749,  0.29594776,  0.84890019,  0.55052446,  0.57301156],\n",
      "       [ 0.04446192,  0.97826943,  0.2095769 ,  0.44577162,  0.06187271,\n",
      "         0.75005411,  0.80418127,  0.00257541,  0.19725846,  0.98981094],\n",
      "       [ 0.39024929,  0.04417675,  0.73576474,  0.47088728,  0.55466637,\n",
      "         0.20010539,  0.17266458,  0.66769516,  0.57348887,  0.29107571]]), array([[ 0.97518871, -0.94649496,  0.98060156, -0.23663888,  0.96062408,\n",
      "        -0.83175304,  0.51614139,  0.99851158,  0.62399646, -0.92413333],\n",
      "       [ 0.60341435,  0.68636017,  0.10214583,  0.38783975,  0.93126019,\n",
      "        -0.30102939, -0.95352647,  0.71764695,  0.81177365,  0.82779959],\n",
      "       [ 0.99321388, -0.36251413,  0.4909557 , -0.7065168 ,  0.98529906,\n",
      "        -0.97569937, -0.72363409,  0.99437195, -0.26066966, -0.83326783],\n",
      "       [-0.94825659,  0.99952967, -0.87898977,  0.98257819, -0.57205556,\n",
      "         0.9990678 , -0.28637562, -0.98840883,  0.97380572,  0.99815131],\n",
      "       [ 0.9483852 ,  0.99182329,  0.89763069,  0.99854953,  0.98677822,\n",
      "         0.99982464,  0.8042706 ,  0.99630988,  0.99943889,  0.89753492]]), array([[ 0.27714249,  0.12150416,  0.20985562,  0.09789025,  0.1757602 ,\n",
      "         0.0694214 ,  0.27068544,  0.18778781,  0.07226396,  0.19917735],\n",
      "       [ 0.80299698,  0.86397783,  0.75095967,  0.93335246,  0.86715893,\n",
      "         0.95215014,  0.79079675,  0.90228428,  0.93766595,  0.80118522],\n",
      "       [ 0.65613325,  0.2342822 ,  0.78363943,  0.54056527,  0.8076381 ,\n",
      "         0.24859773,  0.233121  ,  0.82915479,  0.72439647,  0.71583414],\n",
      "       [ 0.60639291,  0.90019924,  0.24984464,  0.58542779,  0.73719517,\n",
      "         0.64218327,  0.20086661,  0.58631069,  0.71718522,  0.75046632],\n",
      "       [ 0.1100643 ,  0.28100378,  0.24296011,  0.16176866,  0.06840479,\n",
      "         0.21535813,  0.65348053,  0.0492965 ,  0.09304962,  0.26961648]]), array([[-1.07296862,  1.46210794, -0.87785842,  0.90085595, -0.39675353,\n",
      "         1.65980218, -0.63699565, -1.1425182 ,  0.88514116,  1.13162939],\n",
      "       [ 0.87616892, -0.22232814,  0.37756379,  0.42349435,  1.2245077 ,\n",
      "        -0.26621851, -1.31228341,  1.27375593,  0.86334532,  0.52057634],\n",
      "       [ 0.75041164, -0.31011677, -0.11905419,  0.49521132,  0.90148689,\n",
      "         0.68006984, -0.61736206,  1.90465871,  1.04444209, -1.65072127]]), {'Wf': array([[ 0.10622272, -1.52568032,  0.79502609, -0.37443832,  0.1340482 ,\n",
      "         1.20205486,  0.28474811,  0.26246745],\n",
      "       [ 0.2764993 , -0.7332716 ,  0.83600472,  1.54335911,  0.75880566,\n",
      "         0.88490881, -0.87728152, -0.86778722],\n",
      "       [-1.44087602,  1.23225307, -0.25417987,  1.39984394, -0.78191168,\n",
      "        -0.43750898,  0.09542509,  0.92145007],\n",
      "       [ 0.0607502 ,  0.21112476,  0.01652757,  0.17718772, -1.11647002,\n",
      "         0.0809271 , -0.18657899, -0.05682448],\n",
      "       [ 0.49233656, -0.68067814, -0.08450803, -0.29736188,  0.417302  ,\n",
      "         0.78477065, -0.95542526,  0.58591043]]), 'Wi': array([[ 1.62284909,  0.01335268, -0.6946936 ,  0.6218035 , -0.59980453,\n",
      "         1.12341216,  0.30526704,  1.3887794 ],\n",
      "       [-0.66134424,  3.03085711,  0.82458463,  0.65458015, -0.05118845,\n",
      "        -0.72559712, -0.86776868, -0.13597733],\n",
      "       [-0.79726979,  0.28267571, -0.82609743,  0.6210827 ,  0.9561217 ,\n",
      "        -0.70584051,  1.19268607, -0.23794194],\n",
      "       [ 1.15528789,  0.43816635,  1.12232832, -0.9970198 , -0.10679399,\n",
      "         1.45142926, -0.61803685, -2.03720123],\n",
      "       [-1.94258918, -2.50644065, -2.11416392, -0.41163916,  1.27852808,\n",
      "        -0.44222928,  0.32352735, -0.10999149]]), 'Wo': array([[ 1.01012718,  0.92001793, -0.19505734,  0.80539342, -0.70134443,\n",
      "        -0.53722302,  0.15626385, -0.19022103],\n",
      "       [-0.44873803, -0.67244804, -0.55749472,  0.93916874, -1.94332341,\n",
      "         0.35249436, -0.23643695,  0.7278135 ],\n",
      "       [ 0.51507361, -2.78253447,  0.58464661,  0.32427424,  0.02186284,\n",
      "        -0.46867382,  0.85328122, -0.41302931],\n",
      "       [ 1.83471763,  0.56438286,  2.13782807, -0.785534  , -1.75592564,\n",
      "         0.7147896 ,  0.85270406,  0.0353601 ],\n",
      "       [-1.53879325, -0.44789518,  0.61798553, -0.18417633, -0.11598519,\n",
      "        -0.17545897, -0.93391466, -0.53302033]]), 'Wc': array([[ 0.79452824, -1.87316098,  0.92061512, -0.03536792,  2.11060505,\n",
      "        -1.30653407,  0.07638048,  0.36723181],\n",
      "       [ 1.23289919, -0.42285696,  0.08646441, -2.14246673, -0.83016886,\n",
      "         0.45161595,  1.10417433, -0.28173627],\n",
      "       [ 2.05635552,  1.76024923, -0.06065249, -2.413503  , -1.77756638,\n",
      "        -0.77785883,  1.11584111,  0.31027229],\n",
      "       [-2.09424782, -0.22876583,  1.61336137, -0.37480469, -0.74996962,\n",
      "         2.0546241 ,  0.05340954, -0.4791571 ],\n",
      "       [ 0.35016716,  0.01716473, -0.42914228,  1.20845633,  1.1157018 ,\n",
      "         0.84086156, -0.10288722,  1.14690038]]), 'Wy': array([[ 0.45128402, -1.68405999, -1.1601701 ,  1.35010682, -0.33128317],\n",
      "       [ 0.38653915, -0.85145566,  1.00088142, -0.38483225,  1.45810824]]), 'bf': array([[ 2.06578332],\n",
      "       [-1.47115693],\n",
      "       [-0.8301719 ],\n",
      "       [-0.8805776 ],\n",
      "       [-0.27909772]]), 'bi': array([[ 0.00854895],\n",
      "       [-0.16819884],\n",
      "       [-0.17418034],\n",
      "       [ 0.4611641 ],\n",
      "       [-1.17598267]]), 'bo': array([[-1.42655542],\n",
      "       [ 1.76795995],\n",
      "       [-0.47537288],\n",
      "       [ 0.47761018],\n",
      "       [-1.02188594]]), 'bc': array([[-0.04970258],\n",
      "       [ 0.46664327],\n",
      "       [ 1.03368687],\n",
      "       [ 0.80884436],\n",
      "       [ 1.78975468]]), 'by': array([[-0.53223402],\n",
      "       [ 1.1181334 ]])}), (array([[ 0.04764425, -0.02315795,  0.06174785, -0.15585866,  0.18188261,\n",
      "        -0.14268009,  0.04670678,  0.2453844 ,  0.09876054, -0.09021317],\n",
      "       [ 0.33742911, -0.25997147,  0.17755512, -0.26062176,  0.07889693,\n",
      "        -0.16174929, -0.12307641,  0.18678933, -0.19150502, -0.43888814],\n",
      "       [ 0.12216954,  0.19194727,  0.17812395, -0.01366142,  0.26417833,\n",
      "        -0.2082582 , -0.12310316,  0.65803197,  0.14639404, -0.04618678],\n",
      "       [ 0.60320763, -0.07198395,  0.3389998 , -0.00243377, -0.01840843,\n",
      "         0.43084844,  0.08838875,  0.01510513, -0.08354561,  0.25733257],\n",
      "       [ 0.04633505, -0.16219365,  0.12818863,  0.16020523,  0.03110859,\n",
      "         0.15208633,  0.17794155,  0.00782539,  0.19115827,  0.2145425 ]]), array([[ 0.32489773, -0.03298884,  0.38670734, -0.60143792,  1.91153723,\n",
      "        -1.59132326,  0.58800636,  1.8866207 ,  0.35611026, -0.81029371],\n",
      "       [ 0.41658071, -0.73345068,  0.23059801, -0.31626296,  0.08410692,\n",
      "        -0.1816136 , -0.1397872 ,  0.23400072, -0.24336637, -0.50840057],\n",
      "       [ 0.49567276,  0.29057745,  0.41279553, -0.02574529,  1.03227568,\n",
      "        -0.43723508, -0.19398065,  1.33033413,  0.28175277, -0.24366508],\n",
      "       [ 0.76180848, -0.53852884,  0.51768055, -0.0099263 , -0.0215122 ,\n",
      "         1.08452162,  0.20919069,  0.0155694 , -0.26390242,  1.50384975],\n",
      "       [ 0.35461028, -0.25487799,  0.54585104,  0.65833241,  0.45626684,\n",
      "         0.60842365,  0.92348578,  0.22312735,  0.60581113,  0.45075409]]), array([[ 0.18896522, -0.03046246,  0.03342131, -0.07887489,  0.13965167,\n",
      "        -0.06006673, -0.00909386,  0.15590361,  0.01843266, -0.03303514],\n",
      "       [ 0.19407407,  0.28652419, -0.02310186, -0.07463511,  0.05856306,\n",
      "        -0.20638714, -0.51780505,  0.07190293, -0.08121199, -0.12945372],\n",
      "       [ 0.45623508,  0.01845876,  0.24420065, -0.24790231,  0.51500989,\n",
      "        -0.0239799 , -0.03726765,  0.59522601, -0.09871058, -0.32759264],\n",
      "       [-0.02531204,  0.69611559, -0.02161839,  0.35662858, -0.05146256,\n",
      "         0.48279425, -0.01202097, -0.00293715,  0.19893847,  0.6606636 ],\n",
      "       [ 0.0541676 ,  0.06251229,  0.16681163,  0.10030457,  0.039482  ,\n",
      "         0.11320029,  0.28992853,  0.03469357,  0.07207054,  0.07290125]]), array([[ 0.83253374, -0.25617166,  0.16062589, -1.11478728,  1.08367512,\n",
      "        -1.31385664, -0.03360834,  1.18881672,  0.26083247, -0.16740437],\n",
      "       [ 0.24656518,  0.34466275, -0.03077283, -0.08013564,  0.06763736,\n",
      "        -0.22025283, -0.78363658,  0.07985922, -0.08682834, -0.16300634],\n",
      "       [ 0.85821926,  0.07895222,  0.32234279, -0.49553482,  0.75424409,\n",
      "        -0.09676153, -0.16124708,  0.90323788, -0.1371189 , -0.494319  ],\n",
      "       [-0.04176625,  1.02846153, -0.08674426,  0.70761015, -0.06992232,\n",
      "         0.97708522, -0.05991712, -0.00500959,  0.28484996,  1.37726539],\n",
      "       [ 0.53888703,  0.22624343,  0.84145756,  0.72508539,  0.6582262 ,\n",
      "         0.58409777,  0.47678882,  0.87473807,  1.03157393,  0.27728315]]), array([[ 0.9688812 ,  0.14370805,  0.91827838,  0.73270415,  0.91511519,\n",
      "         0.95288684,  0.9621208 ,  0.94702117,  0.72805488,  0.95386901],\n",
      "       [ 0.24079562,  0.4784006 ,  0.2257906 ,  0.17649916,  0.01405654,\n",
      "         0.59389629,  0.22985041,  0.01869974,  0.21614244,  0.92671875],\n",
      "       [ 0.28543081,  0.29447764,  0.24594403,  0.45533229,  0.81394176,\n",
      "         0.26488228,  0.2213438 ,  0.55369077,  0.31730555,  0.16998467],\n",
      "       [ 0.28812916,  0.31886639,  0.25166317,  0.26622603,  0.23523537,\n",
      "         0.28968856,  0.2097882 ,  0.20689086,  0.27929408,  0.37929292],\n",
      "       [ 0.58933343,  0.02866141,  0.43423854,  0.26440619,  0.57313294,\n",
      "         0.52530627,  0.67108987,  0.14321664,  0.29120572,  0.80512804]]), array([[ 0.8527711 ,  0.0044444 ,  0.47206066,  0.31566485,  0.93613514,\n",
      "         0.6356936 ,  0.69330297,  0.82884021,  0.21873794,  0.66130788],\n",
      "       [ 0.42020622,  0.96038674,  0.44513281,  0.5335497 ,  0.52761677,\n",
      "         0.27154743,  0.12276645,  0.23670186,  0.59327046,  0.40883948],\n",
      "       [ 0.27464743,  0.90042944,  0.46215535,  0.73227814,  0.41971369,\n",
      "         0.4587179 ,  0.41882828,  0.83059192,  0.61639307,  0.15983302],\n",
      "       [ 0.78217456,  0.8771483 ,  0.67216192,  0.27062709,  0.00591578,\n",
      "         0.81598036,  0.33570964,  0.06622433,  0.49089513,  0.98303551],\n",
      "       [ 0.03721172,  0.27553939,  0.1887303 ,  0.50411373,  0.07908302,\n",
      "         0.3041238 ,  0.60709184,  0.09946302,  0.38458887,  0.22830891]]), array([[-0.56489785,  0.86065367,  0.50673161,  0.68227852,  0.9826035 ,\n",
      "        -0.53385241,  0.8947627 ,  0.91789236,  0.75985859, -0.98382597],\n",
      "       [ 0.85007999, -0.93539145,  0.53365248, -0.56624358,  0.15760714,\n",
      "        -0.18709902,  0.32852613,  0.98227944, -0.37857789, -0.87403384],\n",
      "       [ 0.91284503,  0.29688921,  0.72165614,  0.27296692,  0.99678644,\n",
      "        -0.89729366, -0.3779344 ,  0.99955181,  0.52768497, -0.99878255],\n",
      "       [ 0.98934764, -0.98782687,  0.80265018, -0.73278154, -0.85601512,\n",
      "         0.98221875,  0.66057263,  0.25075128, -0.69965926,  0.99840008],\n",
      "       [ 0.99501284, -0.94854841,  0.95616724,  0.92561522,  0.99914901,\n",
      "         0.99167979,  0.99411258,  0.98378574,  0.79412309,  0.99648171]]), array([[ 0.15176773,  0.70224804,  0.16755713,  0.28966136,  0.19001242,\n",
      "         0.15502774,  0.08838276,  0.25692622,  0.28895664,  0.13469633],\n",
      "       [ 0.85631917,  0.41583998,  0.78357664,  0.85136018,  0.94026611,\n",
      "         0.90039374,  0.88618288,  0.81275923,  0.80237441,  0.93639844],\n",
      "       [ 0.26633446,  0.67905982,  0.45574208,  0.53075472,  0.3409547 ,\n",
      "         0.50627984,  0.64255562,  0.75694067,  0.53326007,  0.19328687],\n",
      "       [ 0.93936951,  0.14634645,  0.71232231,  0.24519227,  0.85585253,\n",
      "         0.54203644,  0.42867264,  0.97025925,  0.32389307,  0.28408123],\n",
      "       [ 0.13609629,  0.65007855,  0.25771521,  0.27753057,  0.07284758,\n",
      "         0.2800768 ,  0.24457899,  0.03565149,  0.35323033,  0.50777046]]), array([[ 0.86540763, -2.06014071,  0.04221375, -0.68372786, -0.6871727 ,\n",
      "         0.74204416,  0.19091548, -0.34934272, -0.75439794,  1.51981682],\n",
      "       [ 0.31563495, -0.20075807,  0.12182127,  0.07734007,  0.40349164,\n",
      "         0.03261455, -0.03869551,  1.96710175, -0.1809203 , -1.14434139],\n",
      "       [ 0.52946532, -2.43483776,  0.01740941, -0.17470316,  2.52832571,\n",
      "        -0.3198016 ,  0.5627611 ,  1.1110567 , -0.40087819, -0.89055558]]), {'Wf': array([[ 0.10622272, -1.52568032,  0.79502609, -0.37443832,  0.1340482 ,\n",
      "         1.20205486,  0.28474811,  0.26246745],\n",
      "       [ 0.2764993 , -0.7332716 ,  0.83600472,  1.54335911,  0.75880566,\n",
      "         0.88490881, -0.87728152, -0.86778722],\n",
      "       [-1.44087602,  1.23225307, -0.25417987,  1.39984394, -0.78191168,\n",
      "        -0.43750898,  0.09542509,  0.92145007],\n",
      "       [ 0.0607502 ,  0.21112476,  0.01652757,  0.17718772, -1.11647002,\n",
      "         0.0809271 , -0.18657899, -0.05682448],\n",
      "       [ 0.49233656, -0.68067814, -0.08450803, -0.29736188,  0.417302  ,\n",
      "         0.78477065, -0.95542526,  0.58591043]]), 'Wi': array([[ 1.62284909,  0.01335268, -0.6946936 ,  0.6218035 , -0.59980453,\n",
      "         1.12341216,  0.30526704,  1.3887794 ],\n",
      "       [-0.66134424,  3.03085711,  0.82458463,  0.65458015, -0.05118845,\n",
      "        -0.72559712, -0.86776868, -0.13597733],\n",
      "       [-0.79726979,  0.28267571, -0.82609743,  0.6210827 ,  0.9561217 ,\n",
      "        -0.70584051,  1.19268607, -0.23794194],\n",
      "       [ 1.15528789,  0.43816635,  1.12232832, -0.9970198 , -0.10679399,\n",
      "         1.45142926, -0.61803685, -2.03720123],\n",
      "       [-1.94258918, -2.50644065, -2.11416392, -0.41163916,  1.27852808,\n",
      "        -0.44222928,  0.32352735, -0.10999149]]), 'Wo': array([[ 1.01012718,  0.92001793, -0.19505734,  0.80539342, -0.70134443,\n",
      "        -0.53722302,  0.15626385, -0.19022103],\n",
      "       [-0.44873803, -0.67244804, -0.55749472,  0.93916874, -1.94332341,\n",
      "         0.35249436, -0.23643695,  0.7278135 ],\n",
      "       [ 0.51507361, -2.78253447,  0.58464661,  0.32427424,  0.02186284,\n",
      "        -0.46867382,  0.85328122, -0.41302931],\n",
      "       [ 1.83471763,  0.56438286,  2.13782807, -0.785534  , -1.75592564,\n",
      "         0.7147896 ,  0.85270406,  0.0353601 ],\n",
      "       [-1.53879325, -0.44789518,  0.61798553, -0.18417633, -0.11598519,\n",
      "        -0.17545897, -0.93391466, -0.53302033]]), 'Wc': array([[ 0.79452824, -1.87316098,  0.92061512, -0.03536792,  2.11060505,\n",
      "        -1.30653407,  0.07638048,  0.36723181],\n",
      "       [ 1.23289919, -0.42285696,  0.08646441, -2.14246673, -0.83016886,\n",
      "         0.45161595,  1.10417433, -0.28173627],\n",
      "       [ 2.05635552,  1.76024923, -0.06065249, -2.413503  , -1.77756638,\n",
      "        -0.77785883,  1.11584111,  0.31027229],\n",
      "       [-2.09424782, -0.22876583,  1.61336137, -0.37480469, -0.74996962,\n",
      "         2.0546241 ,  0.05340954, -0.4791571 ],\n",
      "       [ 0.35016716,  0.01716473, -0.42914228,  1.20845633,  1.1157018 ,\n",
      "         0.84086156, -0.10288722,  1.14690038]]), 'Wy': array([[ 0.45128402, -1.68405999, -1.1601701 ,  1.35010682, -0.33128317],\n",
      "       [ 0.38653915, -0.85145566,  1.00088142, -0.38483225,  1.45810824]]), 'bf': array([[ 2.06578332],\n",
      "       [-1.47115693],\n",
      "       [-0.8301719 ],\n",
      "       [-0.8805776 ],\n",
      "       [-0.27909772]]), 'bi': array([[ 0.00854895],\n",
      "       [-0.16819884],\n",
      "       [-0.17418034],\n",
      "       [ 0.4611641 ],\n",
      "       [-1.17598267]]), 'bo': array([[-1.42655542],\n",
      "       [ 1.76795995],\n",
      "       [-0.47537288],\n",
      "       [ 0.47761018],\n",
      "       [-1.02188594]]), 'bc': array([[-0.04970258],\n",
      "       [ 0.46664327],\n",
      "       [ 1.03368687],\n",
      "       [ 0.80884436],\n",
      "       [ 1.78975468]]), 'by': array([[-0.53223402],\n",
      "       [ 1.1181334 ]])}), (array([[  6.04977484e-02,   7.96813160e-02,   1.65451191e-02,\n",
      "          5.37288352e-04,   3.18765539e-01,  -1.76131534e-01,\n",
      "         -1.50620600e-02,   1.84994733e-01,  -2.18132237e-03,\n",
      "         -5.77585791e-02],\n",
      "       [ -5.96982127e-01,   1.07146713e-01,   2.69096646e-01,\n",
      "         -1.74159638e-01,   2.90893181e-01,  -5.66547188e-01,\n",
      "         -2.81819798e-01,  -5.55080468e-01,  -2.65057196e-02,\n",
      "         -3.14697030e-01],\n",
      "       [  4.04829135e-02,   2.65207975e-01,   3.32275591e-01,\n",
      "         -5.43794181e-03,   4.81846016e-01,  -1.32655314e-01,\n",
      "         -3.97490008e-03,   4.29328242e-02,  -9.08542369e-04,\n",
      "         -3.05399548e-01],\n",
      "       [  8.95926511e-03,  -9.65249680e-02,   6.89228099e-01,\n",
      "          1.36584322e-02,  -2.39476955e-01,   6.69603508e-02,\n",
      "          3.87128065e-01,   2.09117784e-01,   4.40935345e-01,\n",
      "          7.30674647e-01],\n",
      "       [  1.49851573e-01,   2.79883648e-02,   3.01849269e-02,\n",
      "          2.10745467e-01,   3.25425577e-02,   4.28621787e-01,\n",
      "          3.55982510e-01,   1.17306193e-01,   1.48219495e-01,\n",
      "          1.27034959e-01]]), array([[ 0.10775829,  0.55102193,  0.06051001,  0.00497237,  1.72256092,\n",
      "        -1.18042444, -0.31225776,  1.94048712, -0.0332874 , -1.52769611],\n",
      "       [-0.88031363,  0.11490806,  0.42490545, -0.19129404,  0.45139032,\n",
      "        -0.85441141, -0.30602923, -0.74055026, -0.02867845, -0.38961377],\n",
      "       [ 0.30041501,  0.52528477,  0.61510863, -0.01421762,  0.99372405,\n",
      "        -0.40315099, -0.05813544,  0.47927459, -0.00414957, -0.46203432],\n",
      "       [ 0.17403542, -0.13261353,  1.07201155,  0.03882057, -0.3166605 ,\n",
      "         0.90984699,  1.04992224,  0.32335827,  0.69722125,  1.3722443 ],\n",
      "       [ 0.21199626,  0.1413471 ,  0.20190862,  0.89993783,  0.17263581,\n",
      "         0.66292789,  1.00873547,  0.20353405,  0.68265156,  0.69954708]]), array([[ 0.04764425, -0.02315795,  0.06174785, -0.15585866,  0.18188261,\n",
      "        -0.14268009,  0.04670678,  0.2453844 ,  0.09876054, -0.09021317],\n",
      "       [ 0.33742911, -0.25997147,  0.17755512, -0.26062176,  0.07889693,\n",
      "        -0.16174929, -0.12307641,  0.18678933, -0.19150502, -0.43888814],\n",
      "       [ 0.12216954,  0.19194727,  0.17812395, -0.01366142,  0.26417833,\n",
      "        -0.2082582 , -0.12310316,  0.65803197,  0.14639404, -0.04618678],\n",
      "       [ 0.60320763, -0.07198395,  0.3389998 , -0.00243377, -0.01840843,\n",
      "         0.43084844,  0.08838875,  0.01510513, -0.08354561,  0.25733257],\n",
      "       [ 0.04633505, -0.16219365,  0.12818863,  0.16020523,  0.03110859,\n",
      "         0.15208633,  0.17794155,  0.00782539,  0.19115827,  0.2145425 ]]), array([[ 0.32489773, -0.03298884,  0.38670734, -0.60143792,  1.91153723,\n",
      "        -1.59132326,  0.58800636,  1.8866207 ,  0.35611026, -0.81029371],\n",
      "       [ 0.41658071, -0.73345068,  0.23059801, -0.31626296,  0.08410692,\n",
      "        -0.1816136 , -0.1397872 ,  0.23400072, -0.24336637, -0.50840057],\n",
      "       [ 0.49567276,  0.29057745,  0.41279553, -0.02574529,  1.03227568,\n",
      "        -0.43723508, -0.19398065,  1.33033413,  0.28175277, -0.24366508],\n",
      "       [ 0.76180848, -0.53852884,  0.51768055, -0.0099263 , -0.0215122 ,\n",
      "         1.08452162,  0.20919069,  0.0155694 , -0.26390242,  1.50384975],\n",
      "       [ 0.35461028, -0.25487799,  0.54585104,  0.65833241,  0.45626684,\n",
      "         0.60842365,  0.92348578,  0.22312735,  0.60581113,  0.45075409]]), array([[ 0.13322484,  0.92797484,  0.9283099 ,  0.92212866,  0.78135868,\n",
      "         0.73794222,  0.98633456,  0.84790116,  0.98356983,  0.99442164],\n",
      "       [ 0.26517188,  0.06232227,  0.42156256,  0.13241449,  0.08984133,\n",
      "         0.79468738,  0.86618528,  0.4780887 ,  0.43991516,  0.82473959],\n",
      "       [ 0.7746838 ,  0.49405002,  0.17473976,  0.46950298,  0.28598996,\n",
      "         0.18146319,  0.13187467,  0.35791513,  0.20447174,  0.04984554],\n",
      "       [ 0.36214727,  0.29208066,  0.26517106,  0.24482083,  0.25893348,\n",
      "         0.33019287,  0.34728218,  0.37072349,  0.27416963,  0.25302174],\n",
      "       [ 0.38957044,  0.50033682,  0.15302321,  0.66825184,  0.16476217,\n",
      "         0.53232012,  0.96154553,  0.83958026,  0.88443646,  0.57089303]]), array([[ 0.06544483,  0.7357739 ,  0.39235786,  0.68800257,  0.26454631,\n",
      "         0.09064509,  0.9102747 ,  0.517556  ,  0.90597509,  0.74375506],\n",
      "       [ 0.9911835 ,  0.29099353,  0.36375043,  0.34917816,  0.57122069,\n",
      "         0.73927789,  0.31444224,  0.92143421,  0.2218779 ,  0.0308026 ],\n",
      "       [ 0.35004084,  0.40500527,  0.77126432,  0.37315634,  0.704096  ,\n",
      "         0.32726114,  0.03272578,  0.04439954,  0.10931228,  0.46425471],\n",
      "       [ 0.10188643,  0.11159569,  0.94745771,  0.13724966,  0.48258118,\n",
      "         0.93753066,  0.97752135,  0.74108579,  0.77409212,  0.99175454],\n",
      "       [ 0.09857074,  0.27403206,  0.13445762,  0.46240657,  0.16177765,\n",
      "         0.43648267,  0.12080047,  0.01647241,  0.14696321,  0.44554686]]), array([[ 0.98516327,  0.79050745, -0.76071941,  0.81333347,  0.86549957,\n",
      "        -0.06751404, -0.98017527,  0.65851663, -0.42335237, -0.97064551],\n",
      "       [-0.99959203,  0.55196542,  0.90087581, -0.42790833,  0.77699223,\n",
      "        -0.96051213, -0.58817673, -0.92510496,  0.35326685,  0.96369476],\n",
      "       [-0.23875686,  0.94251854,  0.70400876, -0.00570841,  0.99205729,\n",
      "        -0.98945115, -0.99476052,  0.07044818, -0.56498732, -0.96905576],\n",
      "       [-0.99965649,  0.22115843,  0.98657454,  0.30055255, -0.64463821,\n",
      "         0.58850947,  0.99974701,  0.42854192,  0.99416498,  0.99998294],\n",
      "       [ 0.74921399,  0.98116966,  0.88043169,  0.9948085 ,  0.60243359,\n",
      "         0.77678167,  0.99968029,  0.98350749,  0.99923043,  0.99252123]]), array([[ 0.56359217,  0.15895389,  0.27376142,  0.10805561,  0.33977351,\n",
      "         0.21282581,  0.04979363,  0.19278867,  0.06555418,  0.06346891],\n",
      "       [ 0.84489394,  0.93655646,  0.67097201,  0.92150721,  0.6876238 ,\n",
      "         0.8170956 ,  0.94946223,  0.88181145,  0.92449162,  0.84817775],\n",
      "       [ 0.13878634,  0.5504884 ,  0.60665983,  0.3825048 ,  0.63488858,\n",
      "         0.34668272,  0.0684501 ,  0.09633484,  0.21894973,  0.70736784],\n",
      "       [ 0.05199825,  0.7321285 ,  0.87220009,  0.35201164,  0.781368  ,\n",
      "         0.09286393,  0.49519044,  0.66909057,  0.73172019,  0.8310651 ],\n",
      "       [ 0.71741725,  0.19932854,  0.15152399,  0.29422728,  0.19037306,\n",
      "         0.73861007,  0.46519159,  0.58428348,  0.24984724,  0.21029485]]), array([[-2.3015387 , -0.3224172 ,  0.58281521, -0.12289023, -0.84520564,\n",
      "        -0.19183555,  2.10025514, -0.20889423,  1.25286816,  2.18557541],\n",
      "       [-2.02220122,  0.18656139,  1.12948391, -0.34385368,  0.59357852,\n",
      "        -1.37311732, -1.61577235, -1.85798186, -0.60392063,  0.80186103],\n",
      "       [ 0.13770121,  1.0388246 , -1.12201873,  0.98633519, -0.24863478,\n",
      "        -1.27255876,  0.24073709,  0.6590498 ,  0.82400562, -1.1191154 ]]), {'Wf': array([[ 0.10622272, -1.52568032,  0.79502609, -0.37443832,  0.1340482 ,\n",
      "         1.20205486,  0.28474811,  0.26246745],\n",
      "       [ 0.2764993 , -0.7332716 ,  0.83600472,  1.54335911,  0.75880566,\n",
      "         0.88490881, -0.87728152, -0.86778722],\n",
      "       [-1.44087602,  1.23225307, -0.25417987,  1.39984394, -0.78191168,\n",
      "        -0.43750898,  0.09542509,  0.92145007],\n",
      "       [ 0.0607502 ,  0.21112476,  0.01652757,  0.17718772, -1.11647002,\n",
      "         0.0809271 , -0.18657899, -0.05682448],\n",
      "       [ 0.49233656, -0.68067814, -0.08450803, -0.29736188,  0.417302  ,\n",
      "         0.78477065, -0.95542526,  0.58591043]]), 'Wi': array([[ 1.62284909,  0.01335268, -0.6946936 ,  0.6218035 , -0.59980453,\n",
      "         1.12341216,  0.30526704,  1.3887794 ],\n",
      "       [-0.66134424,  3.03085711,  0.82458463,  0.65458015, -0.05118845,\n",
      "        -0.72559712, -0.86776868, -0.13597733],\n",
      "       [-0.79726979,  0.28267571, -0.82609743,  0.6210827 ,  0.9561217 ,\n",
      "        -0.70584051,  1.19268607, -0.23794194],\n",
      "       [ 1.15528789,  0.43816635,  1.12232832, -0.9970198 , -0.10679399,\n",
      "         1.45142926, -0.61803685, -2.03720123],\n",
      "       [-1.94258918, -2.50644065, -2.11416392, -0.41163916,  1.27852808,\n",
      "        -0.44222928,  0.32352735, -0.10999149]]), 'Wo': array([[ 1.01012718,  0.92001793, -0.19505734,  0.80539342, -0.70134443,\n",
      "        -0.53722302,  0.15626385, -0.19022103],\n",
      "       [-0.44873803, -0.67244804, -0.55749472,  0.93916874, -1.94332341,\n",
      "         0.35249436, -0.23643695,  0.7278135 ],\n",
      "       [ 0.51507361, -2.78253447,  0.58464661,  0.32427424,  0.02186284,\n",
      "        -0.46867382,  0.85328122, -0.41302931],\n",
      "       [ 1.83471763,  0.56438286,  2.13782807, -0.785534  , -1.75592564,\n",
      "         0.7147896 ,  0.85270406,  0.0353601 ],\n",
      "       [-1.53879325, -0.44789518,  0.61798553, -0.18417633, -0.11598519,\n",
      "        -0.17545897, -0.93391466, -0.53302033]]), 'Wc': array([[ 0.79452824, -1.87316098,  0.92061512, -0.03536792,  2.11060505,\n",
      "        -1.30653407,  0.07638048,  0.36723181],\n",
      "       [ 1.23289919, -0.42285696,  0.08646441, -2.14246673, -0.83016886,\n",
      "         0.45161595,  1.10417433, -0.28173627],\n",
      "       [ 2.05635552,  1.76024923, -0.06065249, -2.413503  , -1.77756638,\n",
      "        -0.77785883,  1.11584111,  0.31027229],\n",
      "       [-2.09424782, -0.22876583,  1.61336137, -0.37480469, -0.74996962,\n",
      "         2.0546241 ,  0.05340954, -0.4791571 ],\n",
      "       [ 0.35016716,  0.01716473, -0.42914228,  1.20845633,  1.1157018 ,\n",
      "         0.84086156, -0.10288722,  1.14690038]]), 'Wy': array([[ 0.45128402, -1.68405999, -1.1601701 ,  1.35010682, -0.33128317],\n",
      "       [ 0.38653915, -0.85145566,  1.00088142, -0.38483225,  1.45810824]]), 'bf': array([[ 2.06578332],\n",
      "       [-1.47115693],\n",
      "       [-0.8301719 ],\n",
      "       [-0.8805776 ],\n",
      "       [-0.27909772]]), 'bi': array([[ 0.00854895],\n",
      "       [-0.16819884],\n",
      "       [-0.17418034],\n",
      "       [ 0.4611641 ],\n",
      "       [-1.17598267]]), 'bo': array([[-1.42655542],\n",
      "       [ 1.76795995],\n",
      "       [-0.47537288],\n",
      "       [ 0.47761018],\n",
      "       [-1.02188594]]), 'bc': array([[-0.04970258],\n",
      "       [ 0.46664327],\n",
      "       [ 1.03368687],\n",
      "       [ 0.80884436],\n",
      "       [ 1.78975468]]), 'by': array([[-0.53223402],\n",
      "       [ 1.1181334 ]])}), (array([[-0.02065435,  0.15360844,  0.10966286,  0.06335734,  0.24817091,\n",
      "        -0.08326126,  0.04957134,  0.17702051, -0.0452585 , -0.0732209 ],\n",
      "       [-0.49009389,  0.16401769, -0.02914978, -0.05152579, -0.08883536,\n",
      "        -0.09550294,  0.01798944, -0.24432627, -0.50528765, -0.42267308],\n",
      "       [-0.0541948 ,  0.18770469,  0.61214117,  0.29347702,  0.06349692,\n",
      "        -0.16730622,  0.09911164,  0.11569964, -0.03887617, -0.17719854],\n",
      "       [ 0.56292826, -0.03319278,  0.06088768, -0.05277287, -0.3329471 ,\n",
      "         0.01298063,  0.18983041,  0.65114107,  0.24142502,  0.03208916],\n",
      "       [ 0.14317072,  0.01486848,  0.01510601,  0.17211777,  0.05479955,\n",
      "         0.21943416,  0.06752899,  0.0651704 ,  0.31991341,  0.09137085]]), array([[-0.47730729,  1.34014906,  0.20368099,  0.29330883,  1.47135347,\n",
      "        -0.7396646 ,  0.29905055,  1.9278802 , -0.26739254, -0.24599294],\n",
      "       [-0.58625195,  0.17656294, -0.04061356, -0.0655725 , -0.1246473 ,\n",
      "        -0.12028304,  0.02155388, -0.37889439, -0.65548544, -0.4660367 ],\n",
      "       [-0.10186852,  0.84526951,  1.24773867,  0.53556397,  0.38117159,\n",
      "        -0.2068233 ,  0.12918345,  0.12401473, -0.18575635, -0.31626583],\n",
      "       [ 0.99283094, -0.04115625,  0.08363658, -0.15368024, -0.49532119,\n",
      "         0.0779973 ,  0.32764802,  1.03853092,  1.11960668,  0.31640946],\n",
      "       [ 0.54460288,  0.19769663,  0.10185927,  0.73162451,  0.12149676,\n",
      "         1.05837079,  0.82976929,  0.36498382,  0.64507904,  0.96690317]]), array([[  6.04977484e-02,   7.96813160e-02,   1.65451191e-02,\n",
      "          5.37288352e-04,   3.18765539e-01,  -1.76131534e-01,\n",
      "         -1.50620600e-02,   1.84994733e-01,  -2.18132237e-03,\n",
      "         -5.77585791e-02],\n",
      "       [ -5.96982127e-01,   1.07146713e-01,   2.69096646e-01,\n",
      "         -1.74159638e-01,   2.90893181e-01,  -5.66547188e-01,\n",
      "         -2.81819798e-01,  -5.55080468e-01,  -2.65057196e-02,\n",
      "         -3.14697030e-01],\n",
      "       [  4.04829135e-02,   2.65207975e-01,   3.32275591e-01,\n",
      "         -5.43794181e-03,   4.81846016e-01,  -1.32655314e-01,\n",
      "         -3.97490008e-03,   4.29328242e-02,  -9.08542369e-04,\n",
      "         -3.05399548e-01],\n",
      "       [  8.95926511e-03,  -9.65249680e-02,   6.89228099e-01,\n",
      "          1.36584322e-02,  -2.39476955e-01,   6.69603508e-02,\n",
      "          3.87128065e-01,   2.09117784e-01,   4.40935345e-01,\n",
      "          7.30674647e-01],\n",
      "       [  1.49851573e-01,   2.79883648e-02,   3.01849269e-02,\n",
      "          2.10745467e-01,   3.25425577e-02,   4.28621787e-01,\n",
      "          3.55982510e-01,   1.17306193e-01,   1.48219495e-01,\n",
      "          1.27034959e-01]]), array([[ 0.10775829,  0.55102193,  0.06051001,  0.00497237,  1.72256092,\n",
      "        -1.18042444, -0.31225776,  1.94048712, -0.0332874 , -1.52769611],\n",
      "       [-0.88031363,  0.11490806,  0.42490545, -0.19129404,  0.45139032,\n",
      "        -0.85441141, -0.30602923, -0.74055026, -0.02867845, -0.38961377],\n",
      "       [ 0.30041501,  0.52528477,  0.61510863, -0.01421762,  0.99372405,\n",
      "        -0.40315099, -0.05813544,  0.47927459, -0.00414957, -0.46203432],\n",
      "       [ 0.17403542, -0.13261353,  1.07201155,  0.03882057, -0.3166605 ,\n",
      "         0.90984699,  1.04992224,  0.32335827,  0.69722125,  1.3722443 ],\n",
      "       [ 0.21199626,  0.1413471 ,  0.20190862,  0.89993783,  0.17263581,\n",
      "         0.66292789,  1.00873547,  0.20353405,  0.68265156,  0.69954708]]), array([[ 0.99371025,  0.91611041,  0.63408697,  0.78481982,  0.7360927 ,\n",
      "         0.87472755,  0.94936633,  0.9716361 ,  0.88882158,  0.70856246],\n",
      "       [ 0.70884775,  0.01744455,  0.13279183,  0.09810385,  0.22974649,\n",
      "         0.10709278,  0.17866451,  0.56993393,  0.79590147,  0.03690941],\n",
      "       [ 0.07664879,  0.76584262,  0.61154157,  0.35904566,  0.23420138,\n",
      "         0.31542627,  0.35936974,  0.03809164,  0.2282816 ,  0.90756369],\n",
      "       [ 0.27406869,  0.24435585,  0.26654468,  0.22334606,  0.32670738,\n",
      "         0.16407523,  0.18461852,  0.23677786,  0.33833792,  0.23133391],\n",
      "       [ 0.87224061,  0.57282244,  0.04802875,  0.32588632,  0.56680501,\n",
      "         0.34887243,  0.2945052 ,  0.18223508,  0.7144268 ,  0.44371087]]), array([[ 0.87664844,  0.93145141,  0.20262518,  0.29976131,  0.26872509,\n",
      "         0.29449206,  0.70628382,  0.2905791 ,  0.40380778,  0.84062008],\n",
      "       [ 0.04756617,  0.47087807,  0.76648839,  0.47736185,  0.89777927,\n",
      "         0.17822882,  0.13250735,  0.04378489,  0.69101873,  0.46084386],\n",
      "       [ 0.13112494,  0.44523865,  0.91690083,  0.65753462,  0.15391098,\n",
      "         0.78497341,  0.821736  ,  0.76414168,  0.18863045,  0.7660755 ],\n",
      "       [ 0.94548165,  0.01371972,  0.26809514,  0.18589423,  0.79354603,\n",
      "         0.08518871,  0.23172087,  0.97495453,  0.9334412 ,  0.00103854],\n",
      "       [ 0.3602861 ,  0.11685562,  0.13025351,  0.48481848,  0.03032381,\n",
      "         0.86378538,  0.53559523,  0.53707465,  0.15998575,  0.65696121]]), array([[-0.66661592,  0.89682845,  0.81585306,  0.96545618,  0.75686624,\n",
      "         0.99454351,  0.84314201,  0.14602863, -0.58890887,  0.99506922],\n",
      "       [ 0.79376557,  0.37070832, -0.12660013, -0.09805102, -0.25435277,\n",
      "        -0.16148759,  0.57529215,  0.98596409, -0.91554714, -0.98006359],\n",
      "       [-0.95248829,  0.99493618,  0.95056537,  0.82226658,  0.9644539 ,\n",
      "        -0.10147973,  0.18263234,  0.13840153, -0.97974149,  0.13452948],\n",
      "       [ 0.99963154, -0.63786695, -0.75384578, -0.87334965, -0.49381617,\n",
      "        -0.8368016 ,  0.57747467,  0.98667867,  0.94672304, -0.99868739],\n",
      "       [ 0.99834864,  0.99892363,  0.70755752,  0.90414681,  0.77978048,\n",
      "         0.95752202,  0.9945784 ,  0.6105162 ,  0.98367802,  0.99930789]]), array([[ 0.04650996,  0.17621547,  0.54582992,  0.22216815,  0.27579592,\n",
      "         0.13238295,  0.17067465,  0.18467305,  0.17327347,  0.30363435],\n",
      "       [ 0.92962613,  0.93858057,  0.7181298 ,  0.78690949,  0.71638105,\n",
      "         0.79781056,  0.83475597,  0.67540662,  0.8782248 ,  0.97168127],\n",
      "       [ 0.53384635,  0.27259279,  0.72216409,  0.59939421,  0.17457422,\n",
      "         0.82043465,  0.77147935,  0.93772873,  0.21168746,  0.57884075],\n",
      "       [ 0.74209446,  0.80696182,  0.72969966,  0.34609311,  0.72627755,\n",
      "         0.1667614 ,  0.59995862,  0.83768812,  0.29900351,  0.10477862],\n",
      "       [ 0.28838071,  0.07618583,  0.1488153 ,  0.27580403,  0.45325428,\n",
      "         0.27951989,  0.09925594,  0.18641615,  0.56288309,  0.12226137]]), array([[ 1.74481176, -0.38405435, -1.10061918, -0.93576943, -0.67124613,\n",
      "        -0.88762896,  0.12015895,  0.58662319,  0.51292982, -1.39649634],\n",
      "       [-0.30620401,  0.41005165,  1.19891788,  0.04359686, -1.09491185,\n",
      "         0.31515939,  1.12141771,  1.23616403, -1.23005814,  0.0465673 ],\n",
      "       [ 0.07782113,  2.18697965, -0.51709446,  0.2135339 ,  0.04366899,\n",
      "         0.31354772,  0.28066508, -1.62743834, -0.56230543,  1.9560789 ]]), {'Wf': array([[ 0.10622272, -1.52568032,  0.79502609, -0.37443832,  0.1340482 ,\n",
      "         1.20205486,  0.28474811,  0.26246745],\n",
      "       [ 0.2764993 , -0.7332716 ,  0.83600472,  1.54335911,  0.75880566,\n",
      "         0.88490881, -0.87728152, -0.86778722],\n",
      "       [-1.44087602,  1.23225307, -0.25417987,  1.39984394, -0.78191168,\n",
      "        -0.43750898,  0.09542509,  0.92145007],\n",
      "       [ 0.0607502 ,  0.21112476,  0.01652757,  0.17718772, -1.11647002,\n",
      "         0.0809271 , -0.18657899, -0.05682448],\n",
      "       [ 0.49233656, -0.68067814, -0.08450803, -0.29736188,  0.417302  ,\n",
      "         0.78477065, -0.95542526,  0.58591043]]), 'Wi': array([[ 1.62284909,  0.01335268, -0.6946936 ,  0.6218035 , -0.59980453,\n",
      "         1.12341216,  0.30526704,  1.3887794 ],\n",
      "       [-0.66134424,  3.03085711,  0.82458463,  0.65458015, -0.05118845,\n",
      "        -0.72559712, -0.86776868, -0.13597733],\n",
      "       [-0.79726979,  0.28267571, -0.82609743,  0.6210827 ,  0.9561217 ,\n",
      "        -0.70584051,  1.19268607, -0.23794194],\n",
      "       [ 1.15528789,  0.43816635,  1.12232832, -0.9970198 , -0.10679399,\n",
      "         1.45142926, -0.61803685, -2.03720123],\n",
      "       [-1.94258918, -2.50644065, -2.11416392, -0.41163916,  1.27852808,\n",
      "        -0.44222928,  0.32352735, -0.10999149]]), 'Wo': array([[ 1.01012718,  0.92001793, -0.19505734,  0.80539342, -0.70134443,\n",
      "        -0.53722302,  0.15626385, -0.19022103],\n",
      "       [-0.44873803, -0.67244804, -0.55749472,  0.93916874, -1.94332341,\n",
      "         0.35249436, -0.23643695,  0.7278135 ],\n",
      "       [ 0.51507361, -2.78253447,  0.58464661,  0.32427424,  0.02186284,\n",
      "        -0.46867382,  0.85328122, -0.41302931],\n",
      "       [ 1.83471763,  0.56438286,  2.13782807, -0.785534  , -1.75592564,\n",
      "         0.7147896 ,  0.85270406,  0.0353601 ],\n",
      "       [-1.53879325, -0.44789518,  0.61798553, -0.18417633, -0.11598519,\n",
      "        -0.17545897, -0.93391466, -0.53302033]]), 'Wc': array([[ 0.79452824, -1.87316098,  0.92061512, -0.03536792,  2.11060505,\n",
      "        -1.30653407,  0.07638048,  0.36723181],\n",
      "       [ 1.23289919, -0.42285696,  0.08646441, -2.14246673, -0.83016886,\n",
      "         0.45161595,  1.10417433, -0.28173627],\n",
      "       [ 2.05635552,  1.76024923, -0.06065249, -2.413503  , -1.77756638,\n",
      "        -0.77785883,  1.11584111,  0.31027229],\n",
      "       [-2.09424782, -0.22876583,  1.61336137, -0.37480469, -0.74996962,\n",
      "         2.0546241 ,  0.05340954, -0.4791571 ],\n",
      "       [ 0.35016716,  0.01716473, -0.42914228,  1.20845633,  1.1157018 ,\n",
      "         0.84086156, -0.10288722,  1.14690038]]), 'Wy': array([[ 0.45128402, -1.68405999, -1.1601701 ,  1.35010682, -0.33128317],\n",
      "       [ 0.38653915, -0.85145566,  1.00088142, -0.38483225,  1.45810824]]), 'bf': array([[ 2.06578332],\n",
      "       [-1.47115693],\n",
      "       [-0.8301719 ],\n",
      "       [-0.8805776 ],\n",
      "       [-0.27909772]]), 'bi': array([[ 0.00854895],\n",
      "       [-0.16819884],\n",
      "       [-0.17418034],\n",
      "       [ 0.4611641 ],\n",
      "       [-1.17598267]]), 'bo': array([[-1.42655542],\n",
      "       [ 1.76795995],\n",
      "       [-0.47537288],\n",
      "       [ 0.47761018],\n",
      "       [-1.02188594]]), 'bc': array([[-0.04970258],\n",
      "       [ 0.46664327],\n",
      "       [ 1.03368687],\n",
      "       [ 0.80884436],\n",
      "       [ 1.78975468]]), 'by': array([[-0.53223402],\n",
      "       [ 1.1181334 ]])})], array([[[ 1.62434536, -0.61175641, -0.52817175, -1.07296862,  0.86540763,\n",
      "         -2.3015387 ,  1.74481176],\n",
      "        [-0.7612069 ,  0.3190391 , -0.24937038,  1.46210794, -2.06014071,\n",
      "         -0.3224172 , -0.38405435],\n",
      "        [ 1.13376944, -1.09989127, -0.17242821, -0.87785842,  0.04221375,\n",
      "          0.58281521, -1.10061918],\n",
      "        [ 1.14472371,  0.90159072,  0.50249434,  0.90085595, -0.68372786,\n",
      "         -0.12289023, -0.93576943],\n",
      "        [-0.26788808,  0.53035547, -0.69166075, -0.39675353, -0.6871727 ,\n",
      "         -0.84520564, -0.67124613],\n",
      "        [-0.0126646 , -1.11731035,  0.2344157 ,  1.65980218,  0.74204416,\n",
      "         -0.19183555, -0.88762896],\n",
      "        [-0.74715829,  1.6924546 ,  0.05080775, -0.63699565,  0.19091548,\n",
      "          2.10025514,  0.12015895],\n",
      "        [ 0.61720311,  0.30017032, -0.35224985, -1.1425182 , -0.34934272,\n",
      "         -0.20889423,  0.58662319],\n",
      "        [ 0.83898341,  0.93110208,  0.28558733,  0.88514116, -0.75439794,\n",
      "          1.25286816,  0.51292982],\n",
      "        [-0.29809284,  0.48851815, -0.07557171,  1.13162939,  1.51981682,\n",
      "          2.18557541, -1.39649634]],\n",
      "\n",
      "       [[-1.44411381, -0.50446586,  0.16003707,  0.87616892,  0.31563495,\n",
      "         -2.02220122, -0.30620401],\n",
      "        [ 0.82797464,  0.23009474,  0.76201118, -0.22232814, -0.20075807,\n",
      "          0.18656139,  0.41005165],\n",
      "        [ 0.19829972,  0.11900865, -0.67066229,  0.37756379,  0.12182127,\n",
      "          1.12948391,  1.19891788],\n",
      "        [ 0.18515642, -0.37528495, -0.63873041,  0.42349435,  0.07734007,\n",
      "         -0.34385368,  0.04359686],\n",
      "        [-0.62000084,  0.69803203, -0.44712856,  1.2245077 ,  0.40349164,\n",
      "          0.59357852, -1.09491185],\n",
      "        [ 0.16938243,  0.74055645, -0.9537006 , -0.26621851,  0.03261455,\n",
      "         -1.37311732,  0.31515939],\n",
      "        [ 0.84616065, -0.85951594,  0.35054598, -1.31228341, -0.03869551,\n",
      "         -1.61577235,  1.12141771],\n",
      "        [ 0.40890054, -0.02461696, -0.77516162,  1.27375593,  1.96710175,\n",
      "         -1.85798186,  1.23616403],\n",
      "        [ 1.62765075,  0.3380117 , -1.19926803,  0.86334532, -0.1809203 ,\n",
      "         -0.60392063, -1.23005814],\n",
      "        [ 0.5505375 ,  0.79280687, -0.62353073,  0.52057634, -1.14434139,\n",
      "          0.80186103,  0.0465673 ]],\n",
      "\n",
      "       [[-0.18656977, -0.10174587,  0.86888616,  0.75041164,  0.52946532,\n",
      "          0.13770121,  0.07782113],\n",
      "        [ 0.61838026,  0.23249456,  0.68255141, -0.31011677, -2.43483776,\n",
      "          1.0388246 ,  2.18697965],\n",
      "        [ 0.44136444, -0.10015523, -0.13644474, -0.11905419,  0.01740941,\n",
      "         -1.12201873, -0.51709446],\n",
      "        [-0.99702683,  0.24879916, -0.29664115,  0.49521132, -0.17470316,\n",
      "          0.98633519,  0.2135339 ],\n",
      "        [ 2.19069973, -1.89636092, -0.64691669,  0.90148689,  2.52832571,\n",
      "         -0.24863478,  0.04366899],\n",
      "        [-0.22631424,  1.33145711, -0.28730786,  0.68006984, -0.3198016 ,\n",
      "         -1.27255876,  0.31354772],\n",
      "        [ 0.50318481,  1.29322588, -0.11044703, -0.61736206,  0.5627611 ,\n",
      "          0.24073709,  0.28066508],\n",
      "        [-0.0731127 ,  1.16033857,  0.36949272,  1.90465871,  1.1110567 ,\n",
      "          0.6590498 , -1.62743834],\n",
      "        [ 0.60231928,  0.4202822 ,  0.81095167,  1.04444209, -0.40087819,\n",
      "          0.82400562, -0.56230543],\n",
      "        [ 1.95487808, -1.33195167, -1.76068856, -1.65072127, -0.89055558,\n",
      "         -1.1191154 ,  1.9560789 ]]]))\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "x = np.random.randn(3,10,7)\n",
    "a0 = np.random.randn(5,10)\n",
    "Wf = np.random.randn(5, 5+3)\n",
    "bf = np.random.randn(5,1)\n",
    "Wi = np.random.randn(5, 5+3)\n",
    "bi = np.random.randn(5,1)\n",
    "Wo = np.random.randn(5, 5+3)\n",
    "bo = np.random.randn(5,1)\n",
    "Wc = np.random.randn(5, 5+3)\n",
    "bc = np.random.randn(5,1)\n",
    "Wy = np.random.randn(2,5)\n",
    "by = np.random.randn(2,1)\n",
    "\n",
    "parameters = {\"Wf\": Wf, \"Wi\": Wi, \"Wo\": Wo, \"Wc\": Wc, \"Wy\": Wy, \"bf\": bf, \"bi\": bi, \"bo\": bo, \"bc\": bc, \"by\": by}\n",
    "\n",
    "a, y, c, caches = lstm_forward(x, a0, parameters)\n",
    "print(\"a[4][3][6] = \", a[4][3][6])\n",
    "print(\"a.shape = \", a.shape)\n",
    "print(\"y[1][4][3] =\", y[1][4][3])\n",
    "print(\"y.shape = \", y.shape)\n",
    "print(\"caches[1][1[1]] =\", caches[1][1][1])\n",
    "print(\"c[1][2][1]\", c[1][2][1])\n",
    "print(\"len(caches) = \", len(caches))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **a[4][3][6]** =\n",
    "        </td>\n",
    "        <td>\n",
    "           0.172117767533\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **a.shape** =\n",
    "        </td>\n",
    "        <td>\n",
    "           (5, 10, 7)\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **y[1][4][3]** =\n",
    "        </td>\n",
    "        <td>\n",
    "           0.95087346185\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **y.shape** =\n",
    "        </td>\n",
    "        <td>\n",
    "           (2, 10, 7)\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **caches[1][1][1]** =\n",
    "        </td>\n",
    "        <td>\n",
    "           [ 0.82797464  0.23009474  0.76201118 -0.22232814 -0.20075807  0.18656139\n",
    "  0.41005165]\n",
    "        </td>\n",
    "        \n",
    "     </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **c[1][2][1]** =\n",
    "        </td>\n",
    "        <td>\n",
    "           -0.855544916718\n",
    "        </td>\n",
    "    </tr>       \n",
    "        \n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **len(caches)** =\n",
    "        </td>\n",
    "        <td>\n",
    "           2\n",
    "        </td>\n",
    "    </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You have now implemented the forward passes for the basic RNN and the LSTM. When using a deep learning framework, implementing the forward pass is sufficient to build systems that achieve great performance. \n",
    "\n",
    "The rest of this notebook is optional, and will not be graded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Backpropagation in recurrent neural networks (OPTIONAL / UNGRADED)\n",
    "\n",
    "In modern deep learning frameworks, you only have to implement the forward pass, and the framework takes care of the backward pass, so most deep learning engineers do not need to bother with the details of the backward pass. If however you are an expert in calculus and want to see the details of backprop in RNNs, you can work through this optional portion of the notebook. \n",
    "\n",
    "When in an earlier course you implemented a simple (fully connected) neural network, you used backpropagation to compute the derivatives with respect to the cost to update the parameters. Similarly, in recurrent neural networks you can to calculate the derivatives with respect to the cost in order to update the parameters. The backprop equations are quite complicated and we did not derive them in lecture. However, we will briefly present them below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 - Basic RNN  backward pass\n",
    "\n",
    "We will start by computing the backward pass for the basic RNN-cell.\n",
    "\n",
    "<img src=\"images/rnn_cell_backprop.png\" style=\"width:500;height:300px;\"> <br>\n",
    "<caption><center> **Figure 5**: RNN-cell's backward pass. Just like in a fully-connected neural network, the derivative of the cost function $J$ backpropagates through the RNN by following the chain-rule from calculas. The chain-rule is also used to calculate $(\\frac{\\partial J}{\\partial W_{ax}},\\frac{\\partial J}{\\partial W_{aa}},\\frac{\\partial J}{\\partial b})$ to update the parameters $(W_{ax}, W_{aa}, b_a)$. </center></caption>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deriving the one step backward functions: \n",
    "\n",
    "To compute the `rnn_cell_backward` you need to compute the following equations. It is a good exercise to derive them by hand. \n",
    "\n",
    "The derivative of $\\tanh$ is $1-\\tanh(x)^2$. You can find the complete proof [here](https://www.wyzant.com/resources/lessons/math/calculus/derivative_proofs/tanx). Note that: $ \\text{sech}(x)^2 = 1 - \\tanh(x)^2$\n",
    "\n",
    "Similarly for $\\frac{ \\partial a^{\\langle t \\rangle} } {\\partial W_{ax}}, \\frac{ \\partial a^{\\langle t \\rangle} } {\\partial W_{aa}},  \\frac{ \\partial a^{\\langle t \\rangle} } {\\partial b}$, the derivative of  $\\tanh(u)$ is $(1-\\tanh(u)^2)du$. \n",
    "\n",
    "The final two equations also follow same rule and are derived using the $\\tanh$ derivative. Note that the arrangement is done in a way to get the same dimensions to match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rnn_cell_backward(da_next, cache):\n",
    "    \"\"\"\n",
    "    Implements the backward pass for the RNN-cell (single time-step).\n",
    "\n",
    "    Arguments:\n",
    "    da_next -- Gradient of loss with respect to next hidden state\n",
    "    cache -- python dictionary containing useful values (output of rnn_cell_forward())\n",
    "\n",
    "    Returns:\n",
    "    gradients -- python dictionary containing:\n",
    "                        dx -- Gradients of input data, of shape (n_x, m)\n",
    "                        da_prev -- Gradients of previous hidden state, of shape (n_a, m)\n",
    "                        dWax -- Gradients of input-to-hidden weights, of shape (n_a, n_x)\n",
    "                        dWaa -- Gradients of hidden-to-hidden weights, of shape (n_a, n_a)\n",
    "                        dba -- Gradients of bias vector, of shape (n_a, 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve values from cache\n",
    "    (a_next, a_prev, xt, parameters) = cache\n",
    "    \n",
    "    # Retrieve values from parameters\n",
    "    Wax = parameters[\"Wax\"]\n",
    "    Waa = parameters[\"Waa\"]\n",
    "    Wya = parameters[\"Wya\"]\n",
    "    ba = parameters[\"ba\"]\n",
    "    by = parameters[\"by\"]\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "    # compute the gradient of tanh with respect to a_next (≈1 line)\n",
    "    dtanh = (1 - a_next * a_next) * da_next\n",
    "\n",
    "    # compute the gradient of the loss with respect to Wax (≈2 lines)\n",
    "    dxt = np.dot(Wax.T, dtanh)\n",
    "    dWax = np.dot(dtanh, xt.T)\n",
    "\n",
    "    # compute the gradient with respect to Waa (≈2 lines)\n",
    "    da_prev = np.dot(Waa.T, dtanh)\n",
    "    dWaa = np.dot(dtanh, da_prev.T)\n",
    "\n",
    "    # compute the gradient with respect to b (≈1 line)\n",
    "    dba = np.sum(dtanh, keepdims=True, axis=-1)\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Store the gradients in a python dictionary\n",
    "    gradients = {\"dxt\": dxt, \"da_prev\": da_prev, \"dWax\": dWax, \"dWaa\": dWaa, \"dba\": dba}\n",
    "    \n",
    "    return gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradients[\"dxt\"][1][2] = -0.460564103059\n",
      "gradients[\"dxt\"].shape = (3, 10)\n",
      "gradients[\"da_prev\"][2][3] = 0.0842968653807\n",
      "gradients[\"da_prev\"].shape = (5, 10)\n",
      "gradients[\"dWax\"][3][1] = 0.393081873922\n",
      "gradients[\"dWax\"].shape = (5, 3)\n",
      "gradients[\"dWaa\"][1][2] = 0.253572776461\n",
      "gradients[\"dWaa\"].shape = (5, 5)\n",
      "gradients[\"dba\"][4] = [ 0.80517166]\n",
      "gradients[\"dba\"].shape = (5, 1)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "xt = np.random.randn(3,10)\n",
    "a_prev = np.random.randn(5,10)\n",
    "Wax = np.random.randn(5,3)\n",
    "Waa = np.random.randn(5,5)\n",
    "Wya = np.random.randn(2,5)\n",
    "b = np.random.randn(5,1)\n",
    "by = np.random.randn(2,1)\n",
    "parameters = {\"Wax\": Wax, \"Waa\": Waa, \"Wya\": Wya, \"ba\": ba, \"by\": by}\n",
    "\n",
    "a_next, yt, cache = rnn_cell_forward(xt, a_prev, parameters)\n",
    "\n",
    "da_next = np.random.randn(5,10)\n",
    "gradients = rnn_cell_backward(da_next, cache)\n",
    "print(\"gradients[\\\"dxt\\\"][1][2] =\", gradients[\"dxt\"][1][2])\n",
    "print(\"gradients[\\\"dxt\\\"].shape =\", gradients[\"dxt\"].shape)\n",
    "print(\"gradients[\\\"da_prev\\\"][2][3] =\", gradients[\"da_prev\"][2][3])\n",
    "print(\"gradients[\\\"da_prev\\\"].shape =\", gradients[\"da_prev\"].shape)\n",
    "print(\"gradients[\\\"dWax\\\"][3][1] =\", gradients[\"dWax\"][3][1])\n",
    "print(\"gradients[\\\"dWax\\\"].shape =\", gradients[\"dWax\"].shape)\n",
    "print(\"gradients[\\\"dWaa\\\"][1][2] =\", gradients[\"dWaa\"][1][2])\n",
    "print(\"gradients[\\\"dWaa\\\"].shape =\", gradients[\"dWaa\"].shape)\n",
    "print(\"gradients[\\\"dba\\\"][4] =\", gradients[\"dba\"][4])\n",
    "print(\"gradients[\\\"dba\\\"].shape =\", gradients[\"dba\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **gradients[\"dxt\"][1][2]** =\n",
    "        </td>\n",
    "        <td>\n",
    "           -0.460564103059\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **gradients[\"dxt\"].shape** =\n",
    "        </td>\n",
    "        <td>\n",
    "           (3, 10)\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **gradients[\"da_prev\"][2][3]** =\n",
    "        </td>\n",
    "        <td>\n",
    "           0.0842968653807\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **gradients[\"da_prev\"].shape** =\n",
    "        </td>\n",
    "        <td>\n",
    "           (5, 10)\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **gradients[\"dWax\"][3][1]** =\n",
    "        </td>\n",
    "        <td>\n",
    "           0.393081873922\n",
    "        </td>\n",
    "    </tr>\n",
    "            <tr>\n",
    "        <td>\n",
    "            **gradients[\"dWax\"].shape** =\n",
    "        </td>\n",
    "        <td>\n",
    "           (5, 3)\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **gradients[\"dWaa\"][1][2]** = \n",
    "        </td>\n",
    "        <td>\n",
    "           -0.28483955787\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **gradients[\"dWaa\"].shape** =\n",
    "        </td>\n",
    "        <td>\n",
    "           (5, 5)\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **gradients[\"dba\"][4]** = \n",
    "        </td>\n",
    "        <td>\n",
    "           [ 0.80517166]\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **gradients[\"dba\"].shape** = \n",
    "        </td>\n",
    "        <td>\n",
    "           (5, 1)\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backward pass through the RNN\n",
    "\n",
    "Computing the gradients of the cost with respect to $a^{\\langle t \\rangle}$ at every time-step $t$ is useful because it is what helps the gradient backpropagate to the previous RNN-cell. To do so, you need to iterate through all the time steps starting at the end, and at each step, you increment the overall $db_a$, $dW_{aa}$, $dW_{ax}$ and you store $dx$.\n",
    "\n",
    "**Instructions**:\n",
    "\n",
    "Implement the `rnn_backward` function. Initialize the return variables with zeros first and then loop through all the time steps while calling the `rnn_cell_backward` at each time timestep, update the other variables accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rnn_backward(da, caches):\n",
    "    \"\"\"\n",
    "    Implement the backward pass for a RNN over an entire sequence of input data.\n",
    "\n",
    "    Arguments:\n",
    "    da -- Upstream gradients of all hidden states, of shape (n_a, m, T_x)\n",
    "    caches -- tuple containing information from the forward pass (rnn_forward)\n",
    "    \n",
    "    Returns:\n",
    "    gradients -- python dictionary containing:\n",
    "                        dx -- Gradient w.r.t. the input data, numpy-array of shape (n_x, m, T_x)\n",
    "                        da0 -- Gradient w.r.t the initial hidden state, numpy-array of shape (n_a, m)\n",
    "                        dWax -- Gradient w.r.t the input's weight matrix, numpy-array of shape (n_a, n_x)\n",
    "                        dWaa -- Gradient w.r.t the hidden state's weight matrix, numpy-arrayof shape (n_a, n_a)\n",
    "                        dba -- Gradient w.r.t the bias, of shape (n_a, 1)\n",
    "    \"\"\"\n",
    "        \n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    # Retrieve values from the first cache (t=1) of caches (≈2 lines)\n",
    "    (caches, x) = caches\n",
    "    (a1, a0, x1, parameters) = caches[0]\n",
    "    \n",
    "    # Retrieve dimensions from da's and x1's shapes (≈2 lines)\n",
    "    n_a, m, T_x = da.shape\n",
    "    n_x, m = x1.shape\n",
    "    \n",
    "    # initialize the gradients with the right sizes (≈6 lines)\n",
    "    dx = np.zeros((n_x, m, T_x))\n",
    "    dWax = np.zeros((n_a, n_x))\n",
    "    dWaa = np.zeros((n_a, n_a))\n",
    "    dba = np.zeros((n_a, 1))\n",
    "    da0 = np.zeros((n_a, m))\n",
    "    da_prevt = np.zeros((n_a, m))\n",
    "    \n",
    "    # Loop through all the time steps\n",
    "    for t in reversed(range(T_x)):\n",
    "        # Compute gradients at time step t. Choose wisely the \"da_next\" and the \"cache\" to use in the backward propagation step. (≈1 line)\n",
    "        gradients = rnn_cell_backward(da[:,:,t] + da_prevt, caches[t])\n",
    "        # Retrieve derivatives from gradients (≈ 1 line)\n",
    "        dxt, da_prevt, dWaxt, dWaat, dbat = gradients[\"dxt\"], gradients[\"da_prev\"], gradients[\"dWax\"], gradients[\"dWaa\"], gradients[\"dba\"]\n",
    "        # Increment global derivatives w.r.t parameters by adding their derivative at time-step t (≈4 lines)\n",
    "        dx[:, :, t] = dxt\n",
    "        dWax += dWaxt\n",
    "        dWaa += dWaat\n",
    "        dba += dbat\n",
    "        \n",
    "    # Set da0 to the gradient of a which has been backpropagated through all time-steps (≈1 line) \n",
    "    da0 = da_prevt\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Store the gradients in a python dictionary\n",
    "    gradients = {\"dx\": dx, \"da0\": da0, \"dWax\": dWax, \"dWaa\": dWaa,\"dba\": dba}\n",
    "    \n",
    "    return gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradients[\"dx\"][1][2] = [-2.07101689 -0.59255627  0.02466855  0.01483317]\n",
      "gradients[\"dx\"].shape = (3, 10, 4)\n",
      "gradients[\"da0\"][2][3] = -0.314942375127\n",
      "gradients[\"da0\"].shape = (5, 10)\n",
      "gradients[\"dWax\"][3][1] = 11.2641044965\n",
      "gradients[\"dWax\"].shape = (5, 3)\n",
      "gradients[\"dWaa\"][1][2] = 5.60884278841\n",
      "gradients[\"dWaa\"].shape = (5, 5)\n",
      "gradients[\"dba\"][4] = [-0.74747722]\n",
      "gradients[\"dba\"].shape = (5, 1)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "x = np.random.randn(3,10,4)\n",
    "a0 = np.random.randn(5,10)\n",
    "Wax = np.random.randn(5,3)\n",
    "Waa = np.random.randn(5,5)\n",
    "Wya = np.random.randn(2,5)\n",
    "ba = np.random.randn(5,1)\n",
    "by = np.random.randn(2,1)\n",
    "parameters = {\"Wax\": Wax, \"Waa\": Waa, \"Wya\": Wya, \"ba\": ba, \"by\": by}\n",
    "a, y, caches = rnn_forward(x, a0, parameters)\n",
    "da = np.random.randn(5, 10, 4)\n",
    "gradients = rnn_backward(da, caches)\n",
    "\n",
    "print(\"gradients[\\\"dx\\\"][1][2] =\", gradients[\"dx\"][1][2])\n",
    "print(\"gradients[\\\"dx\\\"].shape =\", gradients[\"dx\"].shape)\n",
    "print(\"gradients[\\\"da0\\\"][2][3] =\", gradients[\"da0\"][2][3])\n",
    "print(\"gradients[\\\"da0\\\"].shape =\", gradients[\"da0\"].shape)\n",
    "print(\"gradients[\\\"dWax\\\"][3][1] =\", gradients[\"dWax\"][3][1])\n",
    "print(\"gradients[\\\"dWax\\\"].shape =\", gradients[\"dWax\"].shape)\n",
    "print(\"gradients[\\\"dWaa\\\"][1][2] =\", gradients[\"dWaa\"][1][2])\n",
    "print(\"gradients[\\\"dWaa\\\"].shape =\", gradients[\"dWaa\"].shape)\n",
    "print(\"gradients[\\\"dba\\\"][4] =\", gradients[\"dba\"][4])\n",
    "print(\"gradients[\\\"dba\\\"].shape =\", gradients[\"dba\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **gradients[\"dx\"][1][2]** =\n",
    "        </td>\n",
    "        <td>\n",
    "           [-2.07101689 -0.59255627  0.02466855  0.01483317]\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **gradients[\"dx\"].shape** =\n",
    "        </td>\n",
    "        <td>\n",
    "           (3, 10, 4)\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **gradients[\"da0\"][2][3]** =\n",
    "        </td>\n",
    "        <td>\n",
    "           -0.314942375127\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **gradients[\"da0\"].shape** =\n",
    "        </td>\n",
    "        <td>\n",
    "           (5, 10)\n",
    "        </td>\n",
    "    </tr>\n",
    "         <tr>\n",
    "        <td>\n",
    "            **gradients[\"dWax\"][3][1]** =\n",
    "        </td>\n",
    "        <td>\n",
    "           11.2641044965\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **gradients[\"dWax\"].shape** =\n",
    "        </td>\n",
    "        <td>\n",
    "           (5, 3)\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **gradients[\"dWaa\"][1][2]** = \n",
    "        </td>\n",
    "        <td>\n",
    "           2.30333312658\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **gradients[\"dWaa\"].shape** =\n",
    "        </td>\n",
    "        <td>\n",
    "           (5, 5)\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **gradients[\"dba\"][4]** = \n",
    "        </td>\n",
    "        <td>\n",
    "           [-0.74747722]\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **gradients[\"dba\"].shape** = \n",
    "        </td>\n",
    "        <td>\n",
    "           (5, 1)\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 - LSTM backward pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 One Step backward\n",
    "\n",
    "The LSTM backward pass is slighltly more complicated than the forward one. We have provided you with all the equations for the LSTM backward pass below. (If you enjoy calculus exercises feel free to try deriving these from scratch yourself.) \n",
    "\n",
    "### 3.2.2 gate derivatives\n",
    "\n",
    "$$d \\Gamma_o^{\\langle t \\rangle} = da_{next}*\\tanh(c_{next}) * \\Gamma_o^{\\langle t \\rangle}*(1-\\Gamma_o^{\\langle t \\rangle})\\tag{7}$$\n",
    "\n",
    "$$d\\tilde c^{\\langle t \\rangle} = dc_{next}*\\Gamma_u^{\\langle t \\rangle}+ \\Gamma_o^{\\langle t \\rangle} (1-\\tanh(c_{next})^2) * i_t * da_{next} * \\tilde c^{\\langle t \\rangle} * (1-\\tanh(\\tilde c)^2) \\tag{8}$$\n",
    "\n",
    "$$d\\Gamma_u^{\\langle t \\rangle} = dc_{next}*\\tilde c^{\\langle t \\rangle} + \\Gamma_o^{\\langle t \\rangle} (1-\\tanh(c_{next})^2) * \\tilde c^{\\langle t \\rangle} * da_{next}*\\Gamma_u^{\\langle t \\rangle}*(1-\\Gamma_u^{\\langle t \\rangle})\\tag{9}$$\n",
    "\n",
    "$$d\\Gamma_f^{\\langle t \\rangle} = dc_{next}*\\tilde c_{prev} + \\Gamma_o^{\\langle t \\rangle} (1-\\tanh(c_{next})^2) * c_{prev} * da_{next}*\\Gamma_f^{\\langle t \\rangle}*(1-\\Gamma_f^{\\langle t \\rangle})\\tag{10}$$\n",
    "\n",
    "### 3.2.3 parameter derivatives \n",
    "\n",
    "$$ dW_f = d\\Gamma_f^{\\langle t \\rangle} * \\begin{pmatrix} a_{prev} \\\\ x_t\\end{pmatrix}^T \\tag{11} $$\n",
    "$$ dW_u = d\\Gamma_u^{\\langle t \\rangle} * \\begin{pmatrix} a_{prev} \\\\ x_t\\end{pmatrix}^T \\tag{12} $$\n",
    "$$ dW_c = d\\tilde c^{\\langle t \\rangle} * \\begin{pmatrix} a_{prev} \\\\ x_t\\end{pmatrix}^T \\tag{13} $$\n",
    "$$ dW_o = d\\Gamma_o^{\\langle t \\rangle} * \\begin{pmatrix} a_{prev} \\\\ x_t\\end{pmatrix}^T \\tag{14}$$\n",
    "\n",
    "To calculate $db_f, db_u, db_c, db_o$ you just need to sum across the horizontal (axis= 1) axis on $d\\Gamma_f^{\\langle t \\rangle}, d\\Gamma_u^{\\langle t \\rangle}, d\\tilde c^{\\langle t \\rangle}, d\\Gamma_o^{\\langle t \\rangle}$ respectively. Note that you should have the `keep_dims = True` option.\n",
    "\n",
    "Finally, you will compute the derivative with respect to the previous hidden state, previous memory state, and input.\n",
    "\n",
    "$$ da_{prev} = W_f^T*d\\Gamma_f^{\\langle t \\rangle} + W_u^T * d\\Gamma_u^{\\langle t \\rangle}+ W_c^T * d\\tilde c^{\\langle t \\rangle} + W_o^T * d\\Gamma_o^{\\langle t \\rangle} \\tag{15}$$\n",
    "Here, the weights for equations 13 are the first n_a, (i.e. $W_f = W_f[:n_a,:]$ etc...)\n",
    "\n",
    "$$ dc_{prev} = dc_{next}\\Gamma_f^{\\langle t \\rangle} + \\Gamma_o^{\\langle t \\rangle} * (1- \\tanh(c_{next})^2)*\\Gamma_f^{\\langle t \\rangle}*da_{next} \\tag{16}$$\n",
    "$$ dx^{\\langle t \\rangle} = W_f^T*d\\Gamma_f^{\\langle t \\rangle} + W_u^T * d\\Gamma_u^{\\langle t \\rangle}+ W_c^T * d\\tilde c_t + W_o^T * d\\Gamma_o^{\\langle t \\rangle}\\tag{17} $$\n",
    "where the weights for equation 15 are from n_a to the end, (i.e. $W_f = W_f[n_a:,:]$ etc...)\n",
    "\n",
    "**Exercise:** Implement `lstm_cell_backward` by implementing equations $7-17$ below. Good luck! :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lstm_cell_backward(da_next, dc_next, cache):\n",
    "    \"\"\"\n",
    "    Implement the backward pass for the LSTM-cell (single time-step).\n",
    "\n",
    "    Arguments:\n",
    "    da_next -- Gradients of next hidden state, of shape (n_a, m)\n",
    "    dc_next -- Gradients of next cell state, of shape (n_a, m)\n",
    "    cache -- cache storing information from the forward pass\n",
    "\n",
    "    Returns:\n",
    "    gradients -- python dictionary containing:\n",
    "                        dxt -- Gradient of input data at time-step t, of shape (n_x, m)\n",
    "                        da_prev -- Gradient w.r.t. the previous hidden state, numpy array of shape (n_a, m)\n",
    "                        dc_prev -- Gradient w.r.t. the previous memory state, of shape (n_a, m, T_x)\n",
    "                        dWf -- Gradient w.r.t. the weight matrix of the forget gate, numpy array of shape (n_a, n_a + n_x)\n",
    "                        dWi -- Gradient w.r.t. the weight matrix of the update gate, numpy array of shape (n_a, n_a + n_x)\n",
    "                        dWc -- Gradient w.r.t. the weight matrix of the memory gate, numpy array of shape (n_a, n_a + n_x)\n",
    "                        dWo -- Gradient w.r.t. the weight matrix of the output gate, numpy array of shape (n_a, n_a + n_x)\n",
    "                        dbf -- Gradient w.r.t. biases of the forget gate, of shape (n_a, 1)\n",
    "                        dbi -- Gradient w.r.t. biases of the update gate, of shape (n_a, 1)\n",
    "                        dbc -- Gradient w.r.t. biases of the memory gate, of shape (n_a, 1)\n",
    "                        dbo -- Gradient w.r.t. biases of the output gate, of shape (n_a, 1)\n",
    "    \"\"\"\n",
    "\n",
    "    # Retrieve information from \"cache\"\n",
    "    (a_next, c_next, a_prev, c_prev, ft, it, cct, ot, xt, parameters) = cache\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    # Retrieve dimensions from xt's and a_next's shape (≈2 lines)\n",
    "    n_x, m = xt.shape\n",
    "    n_a, m = a_next.shape\n",
    "    \n",
    "    # Compute gates related derivatives, you can find their values can be found by looking carefully at equations (7) to (10) (≈4 lines)\n",
    "    dot = da_next * np.tanh(c_next)*ot*(1-ot)\n",
    "    dcct = (dc_next*it+ot*(1-np.square(np.tanh(c_next)))*it*da_next)*(1-np.square(cct))\n",
    "    dit = (dc_next*cct+ot*(1-np.square(np.tanh(c_next)))*cct*da_next)*it*(1-it)\n",
    "    dft = (dc_next*c_prev+ot*(1-np.square(np.tanh(c_next)))*c_prev*da_next)*ft*(1-ft)\n",
    "    \n",
    "    # Code equations (7) to (10) (≈4 lines)\n",
    "    #dit = None\n",
    "    #dft = None\n",
    "    #dot = None\n",
    "    #dcct = None\n",
    "\n",
    "    # Compute parameters related derivatives. Use equations (11)-(14) (≈8 lines)\n",
    "    dWf = np.dot(dft,np.concatenate((a_prev, xt), axis=0).T)\n",
    "    dWi = np.dot(dit,np.concatenate((a_prev, xt), axis=0).T)\n",
    "    dWc = np.dot(dcct,np.concatenate((a_prev, xt), axis=0).T)\n",
    "    dWo = np.dot(dot,np.concatenate((a_prev, xt), axis=0).T)\n",
    "    dbf = np.sum(dft,axis=1,keepdims=True)\n",
    "    dbi = np.sum(dit,axis=1,keepdims=True)\n",
    "    dbc = np.sum(dcct,axis=1,keepdims=True)\n",
    "    dbo = np.sum(dot,axis=1,keepdims=True)\n",
    "\n",
    "    # Compute derivatives w.r.t previous hidden state, previous memory state and input. Use equations (15)-(17). (≈3 lines)\n",
    "    da_prev = np.dot(parameters['Wf'][:,:n_a].T,dft)+np.dot(parameters['Wi'][:,:n_a].T,dit)+np.dot(parameters['Wc'][:,:n_a].T,dcct)+np.dot(parameters['Wo'][:,:n_a].T,dot)\n",
    "    dc_prev = dc_next*ft+ot*(1-np.square(np.tanh(c_next)))*ft*da_next\n",
    "    dxt = np.dot(parameters['Wf'][:,n_a:].T,dft)+np.dot(parameters['Wi'][:,n_a:].T,dit)+np.dot(parameters['Wc'][:,n_a:].T,dcct)+np.dot(parameters['Wo'][:,n_a:].T,dot)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Save gradients in dictionary\n",
    "    gradients = {\"dxt\": dxt, \"da_prev\": da_prev, \"dc_prev\": dc_prev, \"dWf\": dWf,\"dbf\": dbf, \"dWi\": dWi,\"dbi\": dbi,\n",
    "                \"dWc\": dWc,\"dbc\": dbc, \"dWo\": dWo,\"dbo\": dbo}\n",
    "\n",
    "    return gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradients[\"dxt\"][1][2] = 3.23055911511\n",
      "gradients[\"dxt\"].shape = (3, 10)\n",
      "gradients[\"da_prev\"][2][3] = -0.0639621419711\n",
      "gradients[\"da_prev\"].shape = (5, 10)\n",
      "gradients[\"dc_prev\"][2][3] = 0.797522038797\n",
      "gradients[\"dc_prev\"].shape = (5, 10)\n",
      "gradients[\"dWf\"][3][1] = -0.147954838164\n",
      "gradients[\"dWf\"].shape = (5, 8)\n",
      "gradients[\"dWi\"][1][2] = 1.05749805523\n",
      "gradients[\"dWi\"].shape = (5, 8)\n",
      "gradients[\"dWc\"][3][1] = 2.30456216369\n",
      "gradients[\"dWc\"].shape = (5, 8)\n",
      "gradients[\"dWo\"][1][2] = 0.331311595289\n",
      "gradients[\"dWo\"].shape = (5, 8)\n",
      "gradients[\"dbf\"][4] = [ 0.18864637]\n",
      "gradients[\"dbf\"].shape = (5, 1)\n",
      "gradients[\"dbi\"][4] = [-0.40142491]\n",
      "gradients[\"dbi\"].shape = (5, 1)\n",
      "gradients[\"dbc\"][4] = [ 0.25587763]\n",
      "gradients[\"dbc\"].shape = (5, 1)\n",
      "gradients[\"dbo\"][4] = [ 0.13893342]\n",
      "gradients[\"dbo\"].shape = (5, 1)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "xt = np.random.randn(3,10)\n",
    "a_prev = np.random.randn(5,10)\n",
    "c_prev = np.random.randn(5,10)\n",
    "Wf = np.random.randn(5, 5+3)\n",
    "bf = np.random.randn(5,1)\n",
    "Wi = np.random.randn(5, 5+3)\n",
    "bi = np.random.randn(5,1)\n",
    "Wo = np.random.randn(5, 5+3)\n",
    "bo = np.random.randn(5,1)\n",
    "Wc = np.random.randn(5, 5+3)\n",
    "bc = np.random.randn(5,1)\n",
    "Wy = np.random.randn(2,5)\n",
    "by = np.random.randn(2,1)\n",
    "\n",
    "parameters = {\"Wf\": Wf, \"Wi\": Wi, \"Wo\": Wo, \"Wc\": Wc, \"Wy\": Wy, \"bf\": bf, \"bi\": bi, \"bo\": bo, \"bc\": bc, \"by\": by}\n",
    "\n",
    "a_next, c_next, yt, cache = lstm_cell_forward(xt, a_prev, c_prev, parameters)\n",
    "\n",
    "da_next = np.random.randn(5,10)\n",
    "dc_next = np.random.randn(5,10)\n",
    "gradients = lstm_cell_backward(da_next, dc_next, cache)\n",
    "print(\"gradients[\\\"dxt\\\"][1][2] =\", gradients[\"dxt\"][1][2])\n",
    "print(\"gradients[\\\"dxt\\\"].shape =\", gradients[\"dxt\"].shape)\n",
    "print(\"gradients[\\\"da_prev\\\"][2][3] =\", gradients[\"da_prev\"][2][3])\n",
    "print(\"gradients[\\\"da_prev\\\"].shape =\", gradients[\"da_prev\"].shape)\n",
    "print(\"gradients[\\\"dc_prev\\\"][2][3] =\", gradients[\"dc_prev\"][2][3])\n",
    "print(\"gradients[\\\"dc_prev\\\"].shape =\", gradients[\"dc_prev\"].shape)\n",
    "print(\"gradients[\\\"dWf\\\"][3][1] =\", gradients[\"dWf\"][3][1])\n",
    "print(\"gradients[\\\"dWf\\\"].shape =\", gradients[\"dWf\"].shape)\n",
    "print(\"gradients[\\\"dWi\\\"][1][2] =\", gradients[\"dWi\"][1][2])\n",
    "print(\"gradients[\\\"dWi\\\"].shape =\", gradients[\"dWi\"].shape)\n",
    "print(\"gradients[\\\"dWc\\\"][3][1] =\", gradients[\"dWc\"][3][1])\n",
    "print(\"gradients[\\\"dWc\\\"].shape =\", gradients[\"dWc\"].shape)\n",
    "print(\"gradients[\\\"dWo\\\"][1][2] =\", gradients[\"dWo\"][1][2])\n",
    "print(\"gradients[\\\"dWo\\\"].shape =\", gradients[\"dWo\"].shape)\n",
    "print(\"gradients[\\\"dbf\\\"][4] =\", gradients[\"dbf\"][4])\n",
    "print(\"gradients[\\\"dbf\\\"].shape =\", gradients[\"dbf\"].shape)\n",
    "print(\"gradients[\\\"dbi\\\"][4] =\", gradients[\"dbi\"][4])\n",
    "print(\"gradients[\\\"dbi\\\"].shape =\", gradients[\"dbi\"].shape)\n",
    "print(\"gradients[\\\"dbc\\\"][4] =\", gradients[\"dbc\"][4])\n",
    "print(\"gradients[\\\"dbc\\\"].shape =\", gradients[\"dbc\"].shape)\n",
    "print(\"gradients[\\\"dbo\\\"][4] =\", gradients[\"dbo\"][4])\n",
    "print(\"gradients[\\\"dbo\\\"].shape =\", gradients[\"dbo\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **gradients[\"dxt\"][1][2]** =\n",
    "        </td>\n",
    "        <td>\n",
    "           3.23055911511\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **gradients[\"dxt\"].shape** =\n",
    "        </td>\n",
    "        <td>\n",
    "           (3, 10)\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **gradients[\"da_prev\"][2][3]** =\n",
    "        </td>\n",
    "        <td>\n",
    "           -0.0639621419711\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **gradients[\"da_prev\"].shape** =\n",
    "        </td>\n",
    "        <td>\n",
    "           (5, 10)\n",
    "        </td>\n",
    "    </tr>\n",
    "         <tr>\n",
    "        <td>\n",
    "            **gradients[\"dc_prev\"][2][3]** =\n",
    "        </td>\n",
    "        <td>\n",
    "           0.797522038797\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **gradients[\"dc_prev\"].shape** =\n",
    "        </td>\n",
    "        <td>\n",
    "           (5, 10)\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **gradients[\"dWf\"][3][1]** = \n",
    "        </td>\n",
    "        <td>\n",
    "           -0.147954838164\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **gradients[\"dWf\"].shape** =\n",
    "        </td>\n",
    "        <td>\n",
    "           (5, 8)\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **gradients[\"dWi\"][1][2]** = \n",
    "        </td>\n",
    "        <td>\n",
    "           1.05749805523\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **gradients[\"dWi\"].shape** = \n",
    "        </td>\n",
    "        <td>\n",
    "           (5, 8)\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **gradients[\"dWc\"][3][1]** = \n",
    "        </td>\n",
    "        <td>\n",
    "           2.30456216369\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **gradients[\"dWc\"].shape** = \n",
    "        </td>\n",
    "        <td>\n",
    "           (5, 8)\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **gradients[\"dWo\"][1][2]** = \n",
    "        </td>\n",
    "        <td>\n",
    "           0.331311595289\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **gradients[\"dWo\"].shape** = \n",
    "        </td>\n",
    "        <td>\n",
    "           (5, 8)\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **gradients[\"dbf\"][4]** = \n",
    "        </td>\n",
    "        <td>\n",
    "           [ 0.18864637]\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **gradients[\"dbf\"].shape** = \n",
    "        </td>\n",
    "        <td>\n",
    "           (5, 1)\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **gradients[\"dbi\"][4]** = \n",
    "        </td>\n",
    "        <td>\n",
    "           [-0.40142491]\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **gradients[\"dbi\"].shape** = \n",
    "        </td>\n",
    "        <td>\n",
    "           (5, 1)\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **gradients[\"dbc\"][4]** = \n",
    "        </td>\n",
    "        <td>\n",
    "           [ 0.25587763]\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **gradients[\"dbc\"].shape** = \n",
    "        </td>\n",
    "        <td>\n",
    "           (5, 1)\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **gradients[\"dbo\"][4]** = \n",
    "        </td>\n",
    "        <td>\n",
    "           [ 0.13893342]\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **gradients[\"dbo\"].shape** = \n",
    "        </td>\n",
    "        <td>\n",
    "           (5, 1)\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Backward pass through the LSTM RNN\n",
    "\n",
    "This part is very similar to the `rnn_backward` function you implemented above. You will first create variables of the same dimension as your return variables. You will then iterate over all the time steps starting from the end and call the one step function you implemented for LSTM at each iteration. You will then update the parameters by summing them individually. Finally return a dictionary with the new gradients. \n",
    "\n",
    "**Instructions**: Implement the `lstm_backward` function. Create a for loop starting from $T_x$ and going backward. For each step call `lstm_cell_backward` and update the your old gradients by adding the new gradients to them. Note that `dxt` is not updated but is stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_backward(da, caches):\n",
    "    \n",
    "    \"\"\"\n",
    "    Implement the backward pass for the RNN with LSTM-cell (over a whole sequence).\n",
    "\n",
    "    Arguments:\n",
    "    da -- Gradients w.r.t the hidden states, numpy-array of shape (n_a, m, T_x)\n",
    "    dc -- Gradients w.r.t the memory states, numpy-array of shape (n_a, m, T_x)\n",
    "    caches -- cache storing information from the forward pass (lstm_forward)\n",
    "\n",
    "    Returns:\n",
    "    gradients -- python dictionary containing:\n",
    "                        dx -- Gradient of inputs, of shape (n_x, m, T_x)\n",
    "                        da0 -- Gradient w.r.t. the previous hidden state, numpy array of shape (n_a, m)\n",
    "                        dWf -- Gradient w.r.t. the weight matrix of the forget gate, numpy array of shape (n_a, n_a + n_x)\n",
    "                        dWi -- Gradient w.r.t. the weight matrix of the update gate, numpy array of shape (n_a, n_a + n_x)\n",
    "                        dWc -- Gradient w.r.t. the weight matrix of the memory gate, numpy array of shape (n_a, n_a + n_x)\n",
    "                        dWo -- Gradient w.r.t. the weight matrix of the save gate, numpy array of shape (n_a, n_a + n_x)\n",
    "                        dbf -- Gradient w.r.t. biases of the forget gate, of shape (n_a, 1)\n",
    "                        dbi -- Gradient w.r.t. biases of the update gate, of shape (n_a, 1)\n",
    "                        dbc -- Gradient w.r.t. biases of the memory gate, of shape (n_a, 1)\n",
    "                        dbo -- Gradient w.r.t. biases of the save gate, of shape (n_a, 1)\n",
    "    \"\"\"\n",
    "\n",
    "    # Retrieve values from the first cache (t=1) of caches.\n",
    "    (caches, x) = caches\n",
    "    (a1, c1, a0, c0, f1, i1, cc1, o1, x1, parameters) = caches[0]\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    # Retrieve dimensions from da's and x1's shapes (≈2 lines)\n",
    "    n_a, m, T_x = da.shape\n",
    "    n_x, m = x1.shape\n",
    "    \n",
    "    # initialize the gradients with the right sizes (≈12 lines)\n",
    "    dx = np.zeros((n_x, m, T_x))\n",
    "    da0 = np.zeros((n_a, m))\n",
    "    da_prevt = np.zeros((n_a, m))\n",
    "    dc_prevt = np.zeros((n_a, m))\n",
    "    dWf = np.zeros((n_a, n_a+n_x))\n",
    "    dWi = np.zeros((n_a, n_a+n_x))\n",
    "    dWc = np.zeros((n_a, n_a+n_x))\n",
    "    dWo = np.zeros((n_a, n_a+n_x))\n",
    "    dbf = np.zeros((n_a, 1))\n",
    "    dbi = np.zeros((n_a, 1))\n",
    "    dbc = np.zeros((n_a, 1))\n",
    "    dbo = np.zeros((n_a, 1))\n",
    "    \n",
    "    # loop back over the whole sequence\n",
    "    for t in reversed(range(T_x)):\n",
    "        # Compute all gradients using lstm_cell_backward\n",
    "        gradients = lstm_cell_backward(da[:,:,t]+da_prevt, dc_prevt, caches[t])\n",
    "        # Store or add the gradient to the parameters' previous step's gradient\n",
    "        dx[:,:,t] = gradients['dxt']\n",
    "        dWf = dWf + gradients['dWf']\n",
    "        dWi = dWi + gradients['dWi']\n",
    "        dWc = dWc + gradients['dWc']\n",
    "        dWo = dWo + gradients['dWo']\n",
    "        dbf = dbf + gradients['dbf']\n",
    "        dbi = dbi + gradients['dbi']\n",
    "        dbc = dbc + gradients['dbc']\n",
    "        dbo = dbo + gradients['dbo']\n",
    "    # Set the first activation's gradient to the backpropagated gradient da_prev.\n",
    "    da0 = gradients['da_prev']\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Store the gradients in a python dictionary\n",
    "    gradients = {\"dx\": dx, \"da0\": da0, \"dWf\": dWf,\"dbf\": dbf, \"dWi\": dWi,\"dbi\": dbi,\n",
    "                \"dWc\": dWc,\"dbc\": dbc, \"dWo\": dWo,\"dbo\": dbo}\n",
    "    \n",
    "    return gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradients[\"dx\"][1][2] = [-0.00173313  0.08287442 -0.30545663 -0.43281115]\n",
      "gradients[\"dx\"].shape = (3, 10, 4)\n",
      "gradients[\"da0\"][2][3] = -0.095911501954\n",
      "gradients[\"da0\"].shape = (5, 10)\n",
      "gradients[\"dWf\"][3][1] = -0.0698198561274\n",
      "gradients[\"dWf\"].shape = (5, 8)\n",
      "gradients[\"dWi\"][1][2] = 0.102371820249\n",
      "gradients[\"dWi\"].shape = (5, 8)\n",
      "gradients[\"dWc\"][3][1] = -0.0624983794927\n",
      "gradients[\"dWc\"].shape = (5, 8)\n",
      "gradients[\"dWo\"][1][2] = 0.0484389131444\n",
      "gradients[\"dWo\"].shape = (5, 8)\n",
      "gradients[\"dbf\"][4] = [-0.0565788]\n",
      "gradients[\"dbf\"].shape = (5, 1)\n",
      "gradients[\"dbi\"][4] = [-0.15399065]\n",
      "gradients[\"dbi\"].shape = (5, 1)\n",
      "gradients[\"dbc\"][4] = [-0.29691142]\n",
      "gradients[\"dbc\"].shape = (5, 1)\n",
      "gradients[\"dbo\"][4] = [-0.29798344]\n",
      "gradients[\"dbo\"].shape = (5, 1)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "x = np.random.randn(3,10,7)\n",
    "a0 = np.random.randn(5,10)\n",
    "Wf = np.random.randn(5, 5+3)\n",
    "bf = np.random.randn(5,1)\n",
    "Wi = np.random.randn(5, 5+3)\n",
    "bi = np.random.randn(5,1)\n",
    "Wo = np.random.randn(5, 5+3)\n",
    "bo = np.random.randn(5,1)\n",
    "Wc = np.random.randn(5, 5+3)\n",
    "bc = np.random.randn(5,1)\n",
    "\n",
    "parameters = {\"Wf\": Wf, \"Wi\": Wi, \"Wo\": Wo, \"Wc\": Wc, \"Wy\": Wy, \"bf\": bf, \"bi\": bi, \"bo\": bo, \"bc\": bc, \"by\": by}\n",
    "\n",
    "a, y, c, caches = lstm_forward(x, a0, parameters)\n",
    "\n",
    "da = np.random.randn(5, 10, 4)\n",
    "gradients = lstm_backward(da, caches)\n",
    "\n",
    "print(\"gradients[\\\"dx\\\"][1][2] =\", gradients[\"dx\"][1][2])\n",
    "print(\"gradients[\\\"dx\\\"].shape =\", gradients[\"dx\"].shape)\n",
    "print(\"gradients[\\\"da0\\\"][2][3] =\", gradients[\"da0\"][2][3])\n",
    "print(\"gradients[\\\"da0\\\"].shape =\", gradients[\"da0\"].shape)\n",
    "print(\"gradients[\\\"dWf\\\"][3][1] =\", gradients[\"dWf\"][3][1])\n",
    "print(\"gradients[\\\"dWf\\\"].shape =\", gradients[\"dWf\"].shape)\n",
    "print(\"gradients[\\\"dWi\\\"][1][2] =\", gradients[\"dWi\"][1][2])\n",
    "print(\"gradients[\\\"dWi\\\"].shape =\", gradients[\"dWi\"].shape)\n",
    "print(\"gradients[\\\"dWc\\\"][3][1] =\", gradients[\"dWc\"][3][1])\n",
    "print(\"gradients[\\\"dWc\\\"].shape =\", gradients[\"dWc\"].shape)\n",
    "print(\"gradients[\\\"dWo\\\"][1][2] =\", gradients[\"dWo\"][1][2])\n",
    "print(\"gradients[\\\"dWo\\\"].shape =\", gradients[\"dWo\"].shape)\n",
    "print(\"gradients[\\\"dbf\\\"][4] =\", gradients[\"dbf\"][4])\n",
    "print(\"gradients[\\\"dbf\\\"].shape =\", gradients[\"dbf\"].shape)\n",
    "print(\"gradients[\\\"dbi\\\"][4] =\", gradients[\"dbi\"][4])\n",
    "print(\"gradients[\\\"dbi\\\"].shape =\", gradients[\"dbi\"].shape)\n",
    "print(\"gradients[\\\"dbc\\\"][4] =\", gradients[\"dbc\"][4])\n",
    "print(\"gradients[\\\"dbc\\\"].shape =\", gradients[\"dbc\"].shape)\n",
    "print(\"gradients[\\\"dbo\\\"][4] =\", gradients[\"dbo\"][4])\n",
    "print(\"gradients[\\\"dbo\\\"].shape =\", gradients[\"dbo\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **gradients[\"dx\"][1][2]** =\n",
    "        </td>\n",
    "        <td>\n",
    "           [-0.00173313  0.08287442 -0.30545663 -0.43281115]\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **gradients[\"dx\"].shape** =\n",
    "        </td>\n",
    "        <td>\n",
    "           (3, 10, 4)\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **gradients[\"da0\"][2][3]** =\n",
    "        </td>\n",
    "        <td>\n",
    "           -0.095911501954\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **gradients[\"da0\"].shape** =\n",
    "        </td>\n",
    "        <td>\n",
    "           (5, 10)\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **gradients[\"dWf\"][3][1]** = \n",
    "        </td>\n",
    "        <td>\n",
    "           -0.0698198561274\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **gradients[\"dWf\"].shape** =\n",
    "        </td>\n",
    "        <td>\n",
    "           (5, 8)\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **gradients[\"dWi\"][1][2]** = \n",
    "        </td>\n",
    "        <td>\n",
    "           0.102371820249\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **gradients[\"dWi\"].shape** = \n",
    "        </td>\n",
    "        <td>\n",
    "           (5, 8)\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **gradients[\"dWc\"][3][1]** = \n",
    "        </td>\n",
    "        <td>\n",
    "           -0.0624983794927\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **gradients[\"dWc\"].shape** = \n",
    "        </td>\n",
    "        <td>\n",
    "           (5, 8)\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **gradients[\"dWo\"][1][2]** = \n",
    "        </td>\n",
    "        <td>\n",
    "           0.0484389131444\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **gradients[\"dWo\"].shape** = \n",
    "        </td>\n",
    "        <td>\n",
    "           (5, 8)\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **gradients[\"dbf\"][4]** = \n",
    "        </td>\n",
    "        <td>\n",
    "           [-0.0565788]\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **gradients[\"dbf\"].shape** = \n",
    "        </td>\n",
    "        <td>\n",
    "           (5, 1)\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **gradients[\"dbi\"][4]** = \n",
    "        </td>\n",
    "        <td>\n",
    "           [-0.06997391]\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **gradients[\"dbi\"].shape** = \n",
    "        </td>\n",
    "        <td>\n",
    "           (5, 1)\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **gradients[\"dbc\"][4]** = \n",
    "        </td>\n",
    "        <td>\n",
    "           [-0.27441821]\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **gradients[\"dbc\"].shape** = \n",
    "        </td>\n",
    "        <td>\n",
    "           (5, 1)\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **gradients[\"dbo\"][4]** = \n",
    "        </td>\n",
    "        <td>\n",
    "           [ 0.16532821]\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **gradients[\"dbo\"].shape** = \n",
    "        </td>\n",
    "        <td>\n",
    "           (5, 1)\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Congratulations !\n",
    "\n",
    "Congratulations on completing this assignment. You now understand how recurrent neural networks work! \n",
    "\n",
    "Lets go on to the next exercise, where you'll use an RNN to build a character-level language model.\n"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "nlp-sequence-models",
   "graded_item_id": "xxuVc",
   "launcher_item_id": "X20PE"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
